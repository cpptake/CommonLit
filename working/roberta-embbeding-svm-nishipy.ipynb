{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"nishipy-roberta-base-embbeding-svm.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"_uuid":"15c381cd-2a31-4ed7-8d5c-658a46471a46","_cell_guid":"0370cb58-b86e-4c5e-818e-02d66259e073","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-02T15:53:52.038281Z","iopub.execute_input":"2021-07-02T15:53:52.038612Z","iopub.status.idle":"2021-07-02T15:54:01.421155Z","shell.execute_reply.started":"2021-07-02T15:53:52.038569Z","shell.execute_reply":"2021-07-02T15:54:01.420322Z"},"trusted":true,"id":"uXPiBL4T_pBO"},"source":["# !pip uninstall fsspec -y\n","# !pip install --upgrade fsspec\n","# !pip install transformers accelerate datasets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RPkyXrdh__a6","executionInfo":{"status":"ok","timestamp":1626502763603,"user_tz":-540,"elapsed":359,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"93462603-56f0-46a1-d95d-80f10f841ca5"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Sat Jul 17 06:19:24 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s2zcJria__YW","executionInfo":{"status":"ok","timestamp":1626503009085,"user_tz":-540,"elapsed":20650,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"24be1bd3-d3e2-4034-ebdb-7793d7710dd0"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!pip install -q kaggle\n","!mkdir /root/.kaggle\n","!cp /content/drive/MyDrive/Colab\\ Notebooks/kaggle.json /root/.kaggle/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5gjfXAuG__V2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnULirTI__Te","executionInfo":{"status":"ok","timestamp":1626503093492,"user_tz":-540,"elapsed":237,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"27330a6d-49c1-455d-9d9d-098f69cd3de5"},"source":["!mkdir /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy\n","# !unzip -n archive(7)  -d /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base"],"execution_count":5,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUbX04wX__Qu","executionInfo":{"status":"ok","timestamp":1626503221851,"user_tz":-540,"elapsed":48935,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"45640c8f-5a1a-41fb-b82c-93da07122c54"},"source":["!unzip -n /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta_nishipy.zip -d /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Archive:  /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta_nishipy.zip\n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/model_1.pth  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/model_2.pth  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/model_3.pth  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/model_4.pth  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/model_5.pth  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p6t2F6eU__Ny"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ap6Dqiah__Lb","executionInfo":{"status":"ok","timestamp":1626503473572,"user_tz":-540,"elapsed":13345,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"1042c17a-7294-4418-988d-6a16eca7f100"},"source":["!pip install transformers datasets accelerate\n","!pip install transformers\n","!pip install colorama"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 7.1MB/s \n","\u001b[?25hCollecting datasets\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/27/9c91ddee87b06d2de12f134c5171a49890427e398389f07f6463485723c3/datasets-1.9.0-py3-none-any.whl (262kB)\n","\u001b[K     |████████████████████████████████| 266kB 56.0MB/s \n","\u001b[?25hCollecting accelerate\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/fa/d173d923c953d930702066894abf128a7e5258c6f64cf088d2c5a83f46a3/accelerate-0.3.0-py3-none-any.whl (49kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 45.5MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 49.5MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting xxhash\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/4f/0a862cad26aa2ed7a7cd87178cbbfa824fc1383e472d63596a0d018374e7/xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243kB)\n","\u001b[K     |████████████████████████████████| 245kB 55.2MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Collecting fsspec>=2021.05.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/e1/7111d8afc76ee3171f4f99592cd29bac9d233ae1aa34623011506f955434/fsspec-2021.7.0-py3-none-any.whl (118kB)\n","\u001b[K     |████████████████████████████████| 122kB 52.1MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from accelerate) (1.9.0+cu102)\n","Collecting pyaml>=20.4.0\n","  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers, xxhash, fsspec, datasets, pyaml, accelerate\n","Successfully installed accelerate-0.3.0 datasets-1.9.0 fsspec-2021.7.0 huggingface-hub-0.0.12 pyaml-20.4.0 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2 xxhash-2.0.2\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Installing collected packages: colorama\n","Successfully installed colorama-0.4.4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IJt4XGW9_pBQ"},"source":["# Define"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:33.970285Z","iopub.execute_input":"2021-07-15T15:39:33.970705Z","iopub.status.idle":"2021-07-15T15:39:41.078941Z","shell.execute_reply.started":"2021-07-15T15:39:33.970619Z","shell.execute_reply":"2021-07-15T15:39:41.078086Z"},"trusted":true,"id":"9JvMvlfu_pBQ","executionInfo":{"status":"ok","timestamp":1626503478693,"user_tz":-540,"elapsed":5123,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}}},"source":["import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW\n","from transformers import AutoTokenizer\n","from transformers import AutoModel\n","from transformers import AutoConfig\n","from transformers import get_cosine_schedule_with_warmup\n","\n","from sklearn.model_selection import KFold\n","\n","import gc\n","gc.enable()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:41.080356Z","iopub.execute_input":"2021-07-15T15:39:41.080719Z","iopub.status.idle":"2021-07-15T15:39:41.102738Z","shell.execute_reply.started":"2021-07-15T15:39:41.080665Z","shell.execute_reply":"2021-07-15T15:39:41.102069Z"},"trusted":true,"id":"KBUGWWXu_pBR","executionInfo":{"status":"ok","timestamp":1626503479306,"user_tz":-540,"elapsed":615,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}}},"source":["test_df = pd.read_csv(\"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/test.csv\")\n","submission_df = pd.read_csv(\"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/sample_submission.csv\")"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:41.104776Z","iopub.execute_input":"2021-07-15T15:39:41.105244Z","iopub.status.idle":"2021-07-15T15:39:41.152691Z","shell.execute_reply.started":"2021-07-15T15:39:41.105207Z","shell.execute_reply":"2021-07-15T15:39:41.151895Z"},"trusted":true,"id":"R7UVJLp5_pBR","executionInfo":{"status":"ok","timestamp":1626503479306,"user_tz":-540,"elapsed":3,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}}},"source":["NUM_FOLDS = 5\n","NUM_EPOCHS = 3\n","BATCH_SIZE = 16\n","MAX_LEN = 248\n","EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n","ROBERTA_PATH = \"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/huggingface-roberta-variants/roberta-base/\"\n","TOKENIZER_PATH = \"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/huggingface-roberta-variants/roberta-base/\"\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:41.154521Z","iopub.execute_input":"2021-07-15T15:39:41.154919Z","iopub.status.idle":"2021-07-15T15:39:41.382551Z","shell.execute_reply.started":"2021-07-15T15:39:41.154835Z","shell.execute_reply":"2021-07-15T15:39:41.381707Z"},"trusted":true,"id":"8xSPRPc1_pBR","executionInfo":{"status":"ok","timestamp":1626503480789,"user_tz":-540,"elapsed":1485,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}}},"source":["tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:41.383865Z","iopub.execute_input":"2021-07-15T15:39:41.384199Z","iopub.status.idle":"2021-07-15T15:39:41.394234Z","shell.execute_reply.started":"2021-07-15T15:39:41.384162Z","shell.execute_reply":"2021-07-15T15:39:41.393531Z"},"trusted":true,"id":"v7o1-JiB_pBS","executionInfo":{"status":"ok","timestamp":1626503480792,"user_tz":-540,"elapsed":7,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}}},"source":["class LitDataset(Dataset):\n","    def __init__(self, df, inference_only=False):\n","        super().__init__()\n","\n","        self.df = df        \n","        self.inference_only = inference_only\n","        self.text = df.excerpt.tolist()\n","        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n","        \n","        if not self.inference_only:\n","            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n","    \n","        self.encoded = tokenizer.batch_encode_plus(\n","            self.text,\n","            padding = 'max_length',            \n","            max_length = MAX_LEN,\n","            truncation = True,\n","            return_attention_mask=True\n","        )        \n"," \n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    \n","    def __getitem__(self, index):        \n","        input_ids = torch.tensor(self.encoded['input_ids'][index])\n","        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n","        \n","        if self.inference_only:\n","            return (input_ids, attention_mask)            \n","        else:\n","            target = self.target[index]\n","            return (input_ids, attention_mask, target)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:41.395721Z","iopub.execute_input":"2021-07-15T15:39:41.396067Z","iopub.status.idle":"2021-07-15T15:39:41.404884Z","shell.execute_reply.started":"2021-07-15T15:39:41.396029Z","shell.execute_reply":"2021-07-15T15:39:41.404106Z"},"trusted":true,"id":"x96Rywlf_pBS","executionInfo":{"status":"ok","timestamp":1626503480792,"user_tz":-540,"elapsed":6,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}}},"source":["class LitModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n","        config.update({\"output_hidden_states\":True, \n","                       \"hidden_dropout_prob\": 0.0,\n","                       \"layer_norm_eps\": 1e-7})                       \n","        \n","        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n","            \n","        self.attention = nn.Sequential(            \n","            nn.Linear(768, 512),            \n","            nn.Tanh(),                       \n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )        \n","\n","        self.regressor = nn.Sequential(                        \n","            nn.Linear(768, 1)                        \n","        )\n","        \n","\n","    def forward(self, input_ids, attention_mask):\n","        roberta_output = self.roberta(input_ids=input_ids,\n","                                      attention_mask=attention_mask)        \n","\n","        # There are a total of 13 layers of hidden states.\n","        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n","        # We take the hidden states from the last Roberta layer.\n","        last_layer_hidden_states = roberta_output.hidden_states[-1]\n","\n","        # The number of cells is MAX_LEN.\n","        # The size of the hidden state of each cell is 768 (for roberta-base).\n","        # In order to condense hidden states of all cells to a context vector,\n","        # we compute a weighted average of the hidden states of all cells.\n","        # We compute the weight of each cell, using the attention neural network.\n","        weights = self.attention(last_layer_hidden_states)\n","                \n","        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n","        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n","        # Now we compute context_vector as the weighted average.\n","        # context_vector.shape is BATCH_SIZE x 768\n","        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n","        \n","        # Now we reduce the context vector to the prediction score.\n","        \n","        return last_layer_hidden_states\n","#         return self.regressor(context_vector)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:41.40614Z","iopub.execute_input":"2021-07-15T15:39:41.406626Z","iopub.status.idle":"2021-07-15T15:39:41.419648Z","shell.execute_reply.started":"2021-07-15T15:39:41.40659Z","shell.execute_reply":"2021-07-15T15:39:41.418635Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"lIsm2qXF_pBT","executionInfo":{"status":"ok","timestamp":1626503480792,"user_tz":-540,"elapsed":6,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"54d41094-b5b6-49f2-fd00-bbc2133ccb06"},"source":["class CFG:\n","    model_name_or_path = '/content/drive/MyDrive/CommonLit/input/roberta-transformers-pytorch/roberta-base'\n","    #model_name_or_path = '../input/huggingface-bert-variants/bert-base-cased/bert-base-cased/'\n","    clip_by_train_range = False\n","    batch_size = 8\n","    max_seq_length = 512\n","    seq_length = 100\n","    learning_rate = 2e-5\n","    use_lr_scheduler = True\n","    mid_eval = True\n","    mid_eval_step_num = 50\n","    random_seed = 2021\n","    model_output_dir = './'\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    \n","cfg = CFG()\n","seed_everything=(cfg.random_seed)\n","QUICK_CHECK = True\n","\n","global_start_t = time.time()\n","print('ok')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["ok\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:41.42179Z","iopub.execute_input":"2021-07-15T15:39:41.422031Z","iopub.status.idle":"2021-07-15T15:39:41.438608Z","shell.execute_reply.started":"2021-07-15T15:39:41.421998Z","shell.execute_reply":"2021-07-15T15:39:41.437075Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"PAtNhmu0_pBU","executionInfo":{"status":"ok","timestamp":1626503480792,"user_tz":-540,"elapsed":5,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"16b8788f-5439-476a-a230-2be880136274"},"source":["from sklearn.model_selection import KFold,StratifiedKFold\n","\n","\n","# def get_embeddings(df, model_path=cfg.model_name_or_path):\n","#     print('get into get_embeddings()')\n","#     global model, tokenizer, cfg, collate_fn_test\n","    \n","#     model = LitModel(cfg.model_name_or_path)\n","#     model.to(cfg.device)\n","#     model.load_state_dict(torch.load(model_path))\n","#     model.eval()\n","    \n","#     ds = LitDataset(df, tokenizer, cfg.max_seq_length)\n","#     dl = DataLoader(ds, batch_size=2*cfg.batch_size, shuffle=False, \n","#                     collate_fn=collate_fn_test, num_workers=0)\n","# #     (test_dataset, batch_size=BATCH_SIZE,\n","# #                          drop_last=False, shuffle=False, num_workers=2)\n","\n","\n","#     embeddings = []\n","#     with torch.no_grad():\n","#         for i, inputs in enumerate(dl):\n","#             inputs = {key:val.reshape(val.shape[0],-1).to(cfg.device) for key,val in inputs.items()}\n","#             outputs = model.bert(**inputs, return_dict=True)\n","#             outputs = outputs['pooler_output'].detach().cpu().numpy()\n","#             embeddings.extend(outputs)\n","#     del model\n","#     return np.array(embeddings)\n","\n","\n","def get_embeddings(df,path,plot_losses=True, verbose=True):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"{device} is used\")\n","            \n","    model = LitModel()\n","    model.load_state_dict(torch.load(path))\n","    model.to(device)\n","    model.eval()\n","    \n","    tokenizer = AutoTokenizer.from_pretrained('/content/drive/MyDrive/CommonLit/input/roberta-base')\n","    \n","#     ds = LitDataset(df, tokenizer, cfg.max_seq_length)\n","    ds = LitDataset(df, inference_only=True)\n","    dl = DataLoader(ds,\n","                  batch_size = cfg.batch_size,\n","                  shuffle=False,\n","                  num_workers = 4,\n","                  pin_memory=True,\n","                  drop_last=False\n","                 )\n","        \n","    embeddings = list()\n","    with torch.no_grad():\n","        for i, inputs in enumerate(dl):\n","            print(inputs)\n","            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n","            outputs = model(**inputs)\n","            outputs = outputs.detach().cpu().numpy()\n","            embeddings.extend(outputs)\n","    return np.array(embeddings)\n","\n","\n","\n","# def get_preds_svm(X, y, X_test, bins=bins, nfolds=5, C=10, kernel='rbf', gamma='auto'):\n","def get_preds_svm(X, y, X_test, nfolds=5, C=10, kernel='rbf', gamma='auto'):\n","    print('*****'*10 + ' in get_preds_svm() ' + '*****'*10)\n","    print(f'C: {C}, kernel: {kernel}, gamma: {gamma}')\n","    scores = []\n","    preds = np.zeros((X_test.shape[0]))\n","    \n","    \n","    SEED = 1000\n","    kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n","#     kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","    for k, (train_idx, valid_idx) in enumerate(kfold.split(X)):\n","        model = SVR(C=C, kernel=kernel, gamma=gamma)\n","        X_train, y_train = X[train_idx], y[train_idx]\n","        X_valid, y_valid = X[valid_idx], y[valid_idx]\n","        \n","        model.fit(X_train, y_train)\n","        prediction = model.predict(X_valid)\n","        score = rmse_score(prediction, y_valid)\n","        print(f'Fold {k}, rmse_score: {score:.7f}')\n","        scores.append(score)\n","        preds += model.predict(X_test)\n","        \n","    mean_valid_rmse = np.mean(scores)\n","    params = {'C': C, 'kernel': kernel, 'gamma': gamma}\n","    print(f'mean_valid_rmse: {mean_valid_rmse:.7f}')\n","    print('*****'*22)\n","    return mean_valid_rmse, np.array(preds) / nfolds, params\n","\n","print('ok')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["ok\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-15T15:39:41.4404Z","iopub.execute_input":"2021-07-15T15:39:41.440779Z","iopub.status.idle":"2021-07-15T15:40:05.660187Z","shell.execute_reply.started":"2021-07-15T15:39:41.440744Z","shell.execute_reply":"2021-07-15T15:40:05.658705Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":620},"id":"p-YwNAjT_pBU","executionInfo":{"status":"error","timestamp":1626503553950,"user_tz":-540,"elapsed":15917,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"4ce158fa-0838-4ca4-ff04-79df7677182d"},"source":["import tqdm\n","\n","train_df = pd.read_csv('/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/train.csv')\n","\n","train_embeddings1 = get_embeddings(train_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_1.pth')\n","test_embeddings1 = get_embeddings(test_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_1.pth')\n","print(f'train_embeddings1.shape: {train_embeddings1.shape}  test_embeddings1.shape: {test_embeddings1.shape}')\n","\n","train_embeddings2 = get_embeddings(train_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_2.pth')\n","test_embeddings2 = get_embeddings(test_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_2.pth')\n","print(f'train_embeddings2.shape: {train_embeddings2.shape}  test_embeddings2.shape: {test_embeddings2.shape}')\n","\n","train_embeddings3 = get_embeddings(train_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_3.pth')\n","test_embeddings3 = get_embeddings(test_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_3.pth')\n","print(f'train_embeddings3.shape: {train_embeddings3.shape}  test_embeddings3.shape: {test_embeddings3.shape}')\n","\n","train_embeddings4 = get_embeddings(train_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_4.pth')\n","test_embeddings4 = get_embeddings(test_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_4.pth')\n","print(f'train_embeddings4.shape: {train_embeddings4.shape}  test_embeddings4.shape: {test_embeddings4.shape}')\n","\n","train_embeddings5 = get_embeddings(train_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_5.pth')\n","test_embeddings5 = get_embeddings(test_df, '/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_5.pth')\n","print(f'train_embeddings5.shape: {train_embeddings5.shape}  test_embeddings5.shape: {test_embeddings5.shape}')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["cuda is used\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/huggingface-roberta-variants/roberta-base/ were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","404 Client Error: Not Found for url: https://huggingface.co//content/drive/MyDrive/CommonLit/input/roberta-base/resolve/main/config.json\n"],"name":"stderr"},{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1336\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co//content/drive/MyDrive/CommonLit/input/roberta-base/resolve/main/config.json","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-7790040c97ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_embeddings1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_embeddings1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/roberta-base-nishipy/model_1.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'train_embeddings1.shape: {train_embeddings1.shape}  test_embeddings1.shape: {test_embeddings1.shape}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-11ce4ff6b880>\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(df, path, plot_losses, verbose)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/CommonLit/input/roberta-base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#     ds = LitDataset(df, tokenizer, cfg.max_seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m         \"\"\"\n\u001b[1;32m    445\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mconfig_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"- or '{pretrained_model_name_or_path}' is the correct path to a directory containing a {CONFIG_NAME} file\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Can't load config for '/content/drive/MyDrive/CommonLit/input/roberta-base'. Make sure that:\n\n- '/content/drive/MyDrive/CommonLit/input/roberta-base' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or '/content/drive/MyDrive/CommonLit/input/roberta-base' is the correct path to a directory containing a config.json file\n\n"]}]},{"cell_type":"code","metadata":{"id":"cmVsAOTv_pBV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KzilOLL_pBV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oCm48SxR_pBV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BxmV1oC__pBV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4v4xpHlk_pBV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-fCKhxeJ_pBV"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-02T15:55:27.627698Z","iopub.execute_input":"2021-07-02T15:55:27.628026Z","iopub.status.idle":"2021-07-02T15:55:27.635569Z","shell.execute_reply.started":"2021-07-02T15:55:27.627994Z","shell.execute_reply":"2021-07-02T15:55:27.634478Z"},"trusted":true,"id":"0kQNo0PI_pBW"},"source":["def predict(model, data_loader):\n","    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n","    model.eval()\n","\n","    result = np.zeros(len(data_loader.dataset))    \n","    index = 0\n","    \n","    with torch.no_grad():\n","        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","                        \n","            pred = model(input_ids, attention_mask)                        \n","\n","            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n","            index += pred.shape[0]\n","\n","    return result"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HJqOAttt_pBW"},"source":["# Predict and submit"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-02T15:55:29.453323Z","iopub.execute_input":"2021-07-02T15:55:29.453654Z","iopub.status.idle":"2021-07-02T15:56:05.467053Z","shell.execute_reply.started":"2021-07-02T15:55:29.45361Z","shell.execute_reply":"2021-07-02T15:56:05.466088Z"},"trusted":true,"id":"EloJlOy__pBW"},"source":["all_predictions = np.zeros((5, len(test_df)))\n","\n","test_dataset = LitDataset(test_df, inference_only=True)\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n","                         drop_last=False, shuffle=False, num_workers=2)\n","\n","for index in range(5):\n","    #CHANGEME\n","    model_path = f\"/content/drive/MyDrive/CommonLit/input/roberta-base-20210711202147-sche/model_{index + 1}.pth\"\n","    print(f\"\\nUsing {model_path}\")\n","                        \n","    model = LitModel()\n","    model.load_state_dict(torch.load(model_path))    \n","    model.to(DEVICE)\n","    \n","    all_predictions[index] = predict(model, test_loader)\n","    \n","    del model\n","    gc.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-07-02T15:56:10.25547Z","iopub.execute_input":"2021-07-02T15:56:10.255824Z","iopub.status.idle":"2021-07-02T15:56:10.274135Z","shell.execute_reply.started":"2021-07-02T15:56:10.25579Z","shell.execute_reply":"2021-07-02T15:56:10.273373Z"},"trusted":true,"id":"eNarWK0n_pBW"},"source":["predictions = all_predictions.mean(axis=0)\n","submission_df.target = predictions\n","print(submission_df)\n","submission_df.to_csv(\"submission.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vzrrF4BC_pBW"},"source":[""]}]}