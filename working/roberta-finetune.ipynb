{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"finetune-clrp-pytorch-roberta.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"M_81vSz0xaN0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fnwO7IUdsb2A"},"source":["This notebook uses the model created in pretrain any model notebook.\n","\n","1. Pretrain Roberta Model: https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n","2. Finetune Roberta Model: this notebook, <br/>\n","   Finetune Roberta Model TPU: https://www.kaggle.com/maunish/clrp-pytorch-roberta-finetune-tpu\n","3. Inference Notebook: https://www.kaggle.com/maunish/clrp-pytorch-roberta-inference\n","4. Roberta + SVM: https://www.kaggle.com/maunish/clrp-roberta-svm"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3exg1Y1xcjI","executionInfo":{"status":"ok","timestamp":1624893983554,"user_tz":-540,"elapsed":376,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"7cb21da7-cecd-4976-f6a0-f2950b31fd99"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Jun 28 15:26:23 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JrH1uyBxbRg","executionInfo":{"status":"ok","timestamp":1624893990079,"user_tz":-540,"elapsed":4357,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"6afedfd0-e602-448a-9bb5-2d4a97b68b58"},"source":["!pip install -q kaggle\n","!mkdir /root/.kaggle\n","!cp /content/drive/MyDrive/Colab\\ Notebooks/kaggle.json /root/.kaggle/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIP3xyd3xf7D","executionInfo":{"status":"ok","timestamp":1624893990081,"user_tz":-540,"elapsed":10,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"79334112-409c-4fde-8ef6-1f3ebe3f519b"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Iu6Q4vtMTUun"},"source":["# データセット入れる箱\n","# !mkdir /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6BW1Tg3rLdJT"},"source":[""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cQyluMGCxf06","executionInfo":{"status":"ok","timestamp":1624895756207,"user_tz":-540,"elapsed":376989,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"93dd950b-94a7-460d-9789-0c8fb497e7f9"},"source":["!kaggle datasets download -d  takeshikobayashi/clrprobertalarge\n","!unzip -n clrprobertalarge -d /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge\n","# !unzip -n clrprobertalarge -d clrprobertalarge\n","\n","# !kaggle datasets download -d  takeshikobayashi/keras-nn-with-features-neutralization-ver18\n","# !unzip -n keras-nn-with-features-neutralization-ver18 -d keras-nn-with-features-neutralization-ver18"],"execution_count":null,"outputs":[{"output_type":"stream","text":["clrprobertalarge.zip: Skipping, found more recently modified local copy (use --force to force download)\n","Archive:  clrprobertalarge.zip\n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base/config.json  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base/merges.txt  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base/pytorch_model.bin  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base/special_tokens_map.json  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base/tokenizer_config.json  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base/training_args.bin  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base/vocab.json  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1050/config.json  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1050/optimizer.pt  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1050/pytorch_model.bin  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1050/scheduler.pt  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1050/trainer_state.json  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1050/training_args.bin  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1200/config.json  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1200/optimizer.pt  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1200/pytorch_model.bin  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1200/scheduler.pt  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1200/trainer_state.json  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base_chk/checkpoint-1200/training_args.bin  \n","  inflating: /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/text.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59wrVpuPxfvc","executionInfo":{"status":"ok","timestamp":1624895799297,"user_tz":-540,"elapsed":11388,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"1407bdd6-7546-4aff-f34e-61fc4509b7ee"},"source":["!pip install transformers\n","!pip install colorama "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-28T08:30:10.469851Z","iopub.execute_input":"2021-06-28T08:30:10.470265Z","iopub.status.idle":"2021-06-28T08:30:10.483131Z","shell.execute_reply.started":"2021-06-28T08:30:10.470232Z","shell.execute_reply":"2021-06-28T08:30:10.481906Z"},"trusted":true,"id":"4OTl0zoHsb2F"},"source":["import os\n","import gc\n","import sys\n","import math\n","\n","import time\n","import tqdm\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold\n","\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import (AutoModel,AutoTokenizer,get_cosine_schedule_with_warmup)\n","from transformers import PreTrainedModel, RobertaTokenizerFast, RobertaConfig, RobertaModel, AdamW,BertConfig\n","\n","from colorama import Fore, Back, Style\n","r_ = Fore.RED\n","b_ = Fore.BLUE\n","c_ = Fore.CYAN\n","g_ = Fore.GREEN\n","y_ = Fore.YELLOW\n","m_ = Fore.MAGENTA\n","sr_ = Style.RESET_ALL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:30:10.656801Z","iopub.execute_input":"2021-06-28T08:30:10.657136Z","iopub.status.idle":"2021-06-28T08:30:10.716868Z","shell.execute_reply.started":"2021-06-28T08:30:10.657106Z","shell.execute_reply":"2021-06-28T08:30:10.715745Z"},"trusted":true,"id":"oqDNP3owsb2G"},"source":["# train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n","train_data = pd.read_csv('/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/train.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/test.csv')\n","sample = pd.read_csv('/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/sample_submission.csv')\n","\n","num_bins = int(np.floor(1 + np.log2(len(train_data))))\n","train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n","# train_data['excerpt'] = train_data['excerpt'].apply(lambda x: x.replace('\\n',''))\n","\n","bins = train_data.bins.to_numpy()\n","target = train_data.target.to_numpy()\n","\n","def rmse_score(y_true,y_pred):\n","    return np.sqrt(mean_squared_error(y_true,y_pred))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:30:10.844564Z","iopub.execute_input":"2021-06-28T08:30:10.844954Z","iopub.status.idle":"2021-06-28T08:30:10.865589Z","shell.execute_reply.started":"2021-06-28T08:30:10.844922Z","shell.execute_reply":"2021-06-28T08:30:10.864513Z"},"trusted":true,"id":"DTcdiBrwsb2H"},"source":["config = {\n","    'lr': 5e-5,#2e-5\n","    'wd':0.01,\n","    'batch_size':8,#16\n","    'valid_step':5,#10\n","    'max_len':256,\n","    'epochs':3,\n","    'nfolds':5,\n","    'seed':42,\n","}\n","\n","for i in range(config['nfolds']):\n","    os.makedirs(f'model{i}',exist_ok=True)\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONASSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(seed=config['seed'])\n","\n","train_data['Fold'] = -1\n","kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n","for k , (train_idx,valid_idx) in enumerate(kfold.split(X=train_data,y=bins)):\n","    train_data.loc[valid_idx,'Fold'] = k"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:30:11.007437Z","iopub.execute_input":"2021-06-28T08:30:11.008112Z","iopub.status.idle":"2021-06-28T08:30:11.027907Z","shell.execute_reply.started":"2021-06-28T08:30:11.008062Z","shell.execute_reply":"2021-06-28T08:30:11.026648Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":285},"id":"ya69kFMNsb2H","executionInfo":{"status":"ok","timestamp":1624895801324,"user_tz":-540,"elapsed":19,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"653804ce-1e56-4939-84e7-cc48ddc362de"},"source":["train_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>url_legal</th>\n","      <th>license</th>\n","      <th>excerpt</th>\n","      <th>target</th>\n","      <th>standard_error</th>\n","      <th>bins</th>\n","      <th>Fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>c12129c31</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>When the young people returned to the ballroom...</td>\n","      <td>-0.340259</td>\n","      <td>0.464009</td>\n","      <td>7</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>85aa80a4c</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n","      <td>-0.315372</td>\n","      <td>0.480805</td>\n","      <td>7</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>b69ac6792</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>As Roger had predicted, the snow departed as q...</td>\n","      <td>-0.580118</td>\n","      <td>0.476676</td>\n","      <td>6</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>dd1000b26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>And outside before the palace a great garden w...</td>\n","      <td>-1.054013</td>\n","      <td>0.450007</td>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37c1b32fb</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Once upon a time there were Three Bears who li...</td>\n","      <td>0.247197</td>\n","      <td>0.510845</td>\n","      <td>8</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          id url_legal license  ... standard_error  bins  Fold\n","0  c12129c31       NaN     NaN  ...       0.464009     7     0\n","1  85aa80a4c       NaN     NaN  ...       0.480805     7     2\n","2  b69ac6792       NaN     NaN  ...       0.476676     6     3\n","3  dd1000b26       NaN     NaN  ...       0.450007     5     2\n","4  37c1b32fb       NaN     NaN  ...       0.510845     8     1\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:30:11.172975Z","iopub.execute_input":"2021-06-28T08:30:11.173373Z","iopub.status.idle":"2021-06-28T08:30:11.183795Z","shell.execute_reply.started":"2021-06-28T08:30:11.173343Z","shell.execute_reply":"2021-06-28T08:30:11.182386Z"},"trusted":true,"id":"aqWYK6Bssb2J"},"source":["class CLRPDataset(Dataset):\n","    def __init__(self,df,tokenizer,max_len=128):\n","        self.excerpt = df['excerpt'].to_numpy()\n","        self.targets = df['target'].to_numpy()\n","        self.max_len = max_len\n","        self.tokenizer = tokenizer\n","    \n","    def __getitem__(self,idx):\n","        encode = self.tokenizer(self.excerpt[idx],\n","                                return_tensors='pt',\n","                                max_length=self.max_len,\n","                                padding='max_length',\n","                                truncation=True)\n","        \n","        target = torch.tensor(self.targets[idx],dtype=torch.float) \n","        return encode, target\n","    \n","    def __len__(self):\n","        return len(self.excerpt)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:30:11.312355Z","iopub.execute_input":"2021-06-28T08:30:11.312719Z","iopub.status.idle":"2021-06-28T08:30:11.322877Z","shell.execute_reply.started":"2021-06-28T08:30:11.312689Z","shell.execute_reply":"2021-06-28T08:30:11.321766Z"},"trusted":true,"id":"ArmEl645sb2J"},"source":["class AttentionHead(nn.Module):\n","    def __init__(self, in_features, hidden_dim, num_targets):\n","        super().__init__()\n","        self.in_features = in_features\n","        self.middle_features = hidden_dim\n","        self.W = nn.Linear(in_features, hidden_dim)\n","        self.V = nn.Linear(hidden_dim, 1)\n","        self.out_features = hidden_dim\n","\n","    def forward(self, features):\n","        att = torch.tanh(self.W(features))\n","        score = self.V(att)\n","        attention_weights = torch.softmax(score, dim=1)\n","        context_vector = attention_weights * features\n","        context_vector = torch.sum(context_vector, dim=1)\n","\n","        return context_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:30:11.491217Z","iopub.execute_input":"2021-06-28T08:30:11.491649Z","iopub.status.idle":"2021-06-28T08:30:11.501012Z","shell.execute_reply.started":"2021-06-28T08:30:11.491617Z","shell.execute_reply":"2021-06-28T08:30:11.499479Z"},"trusted":true,"id":"CRL-mYeOsb2K"},"source":["class Model(nn.Module):\n","    def __init__(self,path):\n","        super(Model,self).__init__()\n","        self.roberta = AutoModel.from_pretrained(path,output_hidden_states=True)  \n","        self.head = AttentionHead(768,768,1)\n","        self.dropout = nn.Dropout(0.1)\n","#         self.linear = nn.Linear(768,1)\n","#         self.linear=nn.Linear(768,1)#Roberta\n","        self.linear = nn.Linear(1024, 1)#Roberta-large\n","\n","\n","    def forward(self,**xb):\n","\n","########## original ##########        \n","#         x = self.roberta(**xb)[0]\n","#         x = self.head(x)\n","#         x = self.dropout(x)\n","#         x = self.linear(x)\n","#         return x\n","        \n","        output1 = self.roberta(**xb)\n","        output1 = output1.hidden_states\n","        output1 = output1[-1]\n","        output1 = self.dropout(output1)\n","        output1 = torch.mean(output1, 1, True)\n","        final_output = self.linear(output1)\n","        final_outputs = final_output.squeeze(-1).squeeze(-1)\n","        \n","        return final_outputs\n","        \n","        \n","#         output1 = self.roberta(input_ids=ids, attention_mask=mask)\n","#         output1 = output1.hidden_states\n","#         output1 = output1[-1]\n","#         output1 = self.dropout(output1)\n","#         output1 = torch.mean(output1, 1, True)\n","# #         print(output1.size())\n","#         final_output = self.linear(output1)\n","#         final_outputs = final_output.squeeze(-1).squeeze(-1)\n","        \n","#         return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:30:11.664493Z","iopub.execute_input":"2021-06-28T08:30:11.664912Z","iopub.status.idle":"2021-06-28T08:30:11.688631Z","shell.execute_reply.started":"2021-06-28T08:30:11.664881Z","shell.execute_reply":"2021-06-28T08:30:11.687342Z"},"trusted":true,"id":"zBZ9MHjNsb2M"},"source":["def run(fold,verbose=True):\n","    \n","    def loss_fn(outputs,targets):\n","        outputs = outputs.view(-1)\n","        targets = targets.view(-1)\n","        return torch.sqrt(nn.MSELoss()(outputs,targets))\n","    \n","    def train_and_evaluate_loop(train_loader,valid_loader,model,loss_fn, device,optimizer,epoch,fold,best_loss,valid_step=10,lr_scheduler=None):\n","        train_loss = 0\n","        for i, (inputs1,targets1) in enumerate(train_loader):\n","            model.train()\n","            optimizer.zero_grad()\n","#             print(inputs1.shape)\n","            inputs1 = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs1.items()}\n","            targets1 = targets1.to(device)\n","            outputs1 = model(**inputs1)\n","            loss1 = loss_fn(outputs1,targets1)\n","            loss1.backward()\n","            optimizer.step()\n","            \n","            train_loss += loss1.item()\n","            \n","            if lr_scheduler:\n","                lr_scheduler.step()\n","            \n","            #evaluating for every valid_step\n","            if (i % valid_step == 0) or ((i + 1) == len(train_loader)):\n","                model.eval()\n","                valid_loss = 0\n","                with torch.no_grad():\n","                    for j, (inputs2,targets2) in enumerate(valid_loader):\n","                        inputs2 = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs2.items()}\n","                        targets2 = targets2.to(device)\n","                        outputs2 = model(**inputs2)\n","                        loss2 = loss_fn(outputs2,targets2)\n","                        valid_loss += loss2.item()\n","                     \n","                    valid_loss /= len(valid_loader)\n","                    if valid_loss <= best_loss:\n","                        if verbose:\n","                            print(f\"epoch:{epoch} | Train Loss:{train_loss/(i+1)} | Validation loss:{valid_loss}\")\n","                            print(f\"{g_}Validation loss Decreased from {best_loss} to {valid_loss}{sr_}\")\n","\n","                        best_loss = valid_loss\n","                        torch.save(model.state_dict(),f'./model{fold}/model{fold}_ver1.bin')\n","                        torch.save(model.state_dict(),f'./model{fold}/model{fold}_ver1.h5')\n","                        tokenizer.save_pretrained(f'./model{fold}')\n","                        \n","        return best_loss\n","    \n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","                \n","    x_train,x_valid = train_data.query(f\"Fold != {fold}\"),train_data.query(f\"Fold == {fold}\")\n","    print(\"test\")\n","#     MODEL_PATH = f'../input/clrp-roberta-base/clrp_roberta_base'\n","    MODEL_PATH = (f'/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base')\n","    tokenizer = AutoTokenizer.from_pretrained('roberta-large')\n","#     tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n","    model_config = RobertaConfig.from_pretrained('roberta-large')\n","    model_config.output_hidden_states = True\n","    model = Model(MODEL_PATH)\n","    model.to(device)\n","    print(\"test2\")\n","    train_ds = CLRPDataset(x_train,tokenizer,config['max_len'])\n","    train_dl = DataLoader(train_ds,\n","                        batch_size = config[\"batch_size\"],\n","                        shuffle=True,\n","                        num_workers = 4,\n","                        pin_memory=True,\n","                        drop_last=False)\n","    print(\"test3\")\n","    valid_ds = CLRPDataset(x_valid,tokenizer,config['max_len'])\n","    valid_dl = DataLoader(valid_ds,\n","                        batch_size = config[\"batch_size\"],\n","                        shuffle=False,\n","                        num_workers = 4,\n","                        pin_memory=True,\n","                        drop_last=False)\n","\n","    optimizer = optim.AdamW(model.parameters(),lr=config['lr'],weight_decay=config['wd'])\n","    lr_scheduler = get_cosine_schedule_with_warmup(optimizer,num_warmup_steps=0,num_training_steps= 10 * len(train_dl))\n","#     lr_scheduler = None\n","\n","    print(f\"Fold: {fold}\")\n","    best_loss = 9999\n","    for epoch in range(config[\"epochs\"]):\n","        print(f\"Epoch Started:{epoch}\")\n","        best_loss = train_and_evaluate_loop(train_dl,valid_dl,model,loss_fn,\n","                                            device,optimizer,epoch,fold,best_loss,\n","                                            valid_step=config['valid_step'],lr_scheduler=lr_scheduler)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"14cfdearAuWV","executionInfo":{"status":"error","timestamp":1624895879311,"user_tz":-540,"elapsed":36969,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"eaef7cd0-9fec-4ca6-f7b1-2fa2ff1fb8e3"},"source":["tokenizer = AutoTokenizer.from_pretrained('roberta-large')\n","model_config = RobertaConfig.from_pretrained('roberta-large')\n","model_config.output_hidden_states = True\n","model = Model('/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base')\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-d455560f5583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"]}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-28T08:30:11.949844Z","iopub.execute_input":"2021-06-28T08:30:11.950222Z","iopub.status.idle":"2021-06-28T10:57:44.696167Z","shell.execute_reply.started":"2021-06-28T08:30:11.950191Z","shell.execute_reply":"2021-06-28T10:57:44.693480Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":553},"id":"Y4rQG7Ydsb2R","executionInfo":{"status":"error","timestamp":1624895948854,"user_tz":-540,"elapsed":64184,"user":{"displayName":"小林健史","photoUrl":"","userId":"11137570562930914237"}},"outputId":"d6cd9483-cdb2-4726-f9d2-92e08c0d1037"},"source":["for f in range(config['nfolds']):\n","    run(f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["test\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrprobertalarge/clrp_robertalarge_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["test2\n","test3\n","Fold: 0\n","Epoch Started:0\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-1ec8799eb696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nfolds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-25-7455f06401f3>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold, verbose)\u001b[0m\n\u001b[1;32m     88\u001b[0m         best_loss = train_and_evaluate_loop(train_dl,valid_dl,model,loss_fn,\n\u001b[1;32m     89\u001b[0m                                             \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                                             valid_step=config['valid_step'],lr_scheduler=lr_scheduler)\n\u001b[0m","\u001b[0;32m<ipython-input-25-7455f06401f3>\u001b[0m in \u001b[0;36mtrain_and_evaluate_loop\u001b[0;34m(train_loader, valid_loader, model, loss_fn, device, optimizer, epoch, fold, best_loss, valid_step, lr_scheduler)\u001b[0m\n\u001b[1;32m     34\u001b[0m                         \u001b[0moutputs2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0mloss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"ZqXerwFD5RjR"},"source":[""],"execution_count":null,"outputs":[]}]}