{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "pre-trained-roberta-solution-in-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cpptake/CommonLit/blob/main/pre_trained_roberta_solution_in_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhPEM_Gh_WAB"
      },
      "source": [
        "# Overview\n",
        "This is kernel is almost the same as [Lightweight Roberta solution in PyTorch](https://www.kaggle.com/andretugan/lightweight-roberta-solution-in-pytorch), but instead of \"roberta-base\", it starts from [Maunish's pre-trained model](https://www.kaggle.com/maunish/clrp-roberta-base).\n",
        "\n",
        "Acknowledgments: some ideas were taken from kernels by [Torch](https://www.kaggle.com/rhtsingh) and [Maunish](https://www.kaggle.com/maunish).\n",
        "\n",
        "ｺﾊﾞﾔｼNotebook\n",
        "\n",
        "<a>https://www.kaggle.com/takeshikobayashi/pre-trained-roberta-solution-in-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAfsSvDnAldC",
        "outputId": "0b7f523e-084c-4c77-9e78-c47d607f8b91"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jul  3 13:46:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gPlETDFAnaP",
        "outputId": "7718e421-2b8f-40b6-ebd8-f6dc4499a13e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q kaggle\n",
        "!mkdir /root/.kaggle\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/kaggle.json /root/.kaggle/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGGw0o9JAnX3"
      },
      "source": [
        "# !mkdir /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oc7XM36Alaj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMsTrdzOAlYG",
        "outputId": "f77aed5d-ba49-48f1-9918-6debcf9017a4"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install colorama"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.443882Z",
          "iopub.execute_input": "2021-06-30T12:51:59.444296Z",
          "iopub.status.idle": "2021-06-30T12:51:59.453842Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.444253Z",
          "shell.execute_reply": "2021-06-30T12:51:59.452225Z"
        },
        "trusted": true,
        "id": "DTTsyPtZ_WAF"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoConfig\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "\n",
        "import gc\n",
        "gc.enable()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.455842Z",
          "iopub.execute_input": "2021-06-30T12:51:59.456479Z",
          "iopub.status.idle": "2021-06-30T12:51:59.465351Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.456435Z",
          "shell.execute_reply": "2021-06-30T12:51:59.463604Z"
        },
        "trusted": true,
        "id": "bxIwKkUa_WAG"
      },
      "source": [
        "NUM_FOLDS = 5\n",
        "NUM_EPOCHS = 1#3\n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 248\n",
        "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
        "ROBERTA_PATH = \"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base\"\n",
        "TOKENIZER_PATH = \"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.470104Z",
          "iopub.execute_input": "2021-06-30T12:51:59.470538Z",
          "iopub.status.idle": "2021-06-30T12:51:59.4821Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.470504Z",
          "shell.execute_reply": "2021-06-30T12:51:59.480794Z"
        },
        "trusted": true,
        "id": "BfG-bwZd_WAG"
      },
      "source": [
        "def set_random_seed(random_seed):\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
        "\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.484595Z",
          "iopub.execute_input": "2021-06-30T12:51:59.485434Z",
          "iopub.status.idle": "2021-06-30T12:51:59.534929Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.485325Z",
          "shell.execute_reply": "2021-06-30T12:51:59.533897Z"
        },
        "trusted": true,
        "id": "jLfPOtW4_WAH"
      },
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/train.csv\")\n",
        "\n",
        "# Remove incomplete entries if any.\n",
        "train_df.drop(train_df[(train_df.target == 0) & (train_df.standard_error == 0)].index,\n",
        "              inplace=True)\n",
        "train_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/test.csv\")\n",
        "submission_df = pd.read_csv(\"/content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.536957Z",
          "iopub.execute_input": "2021-06-30T12:51:59.537235Z",
          "iopub.status.idle": "2021-06-30T12:51:59.793967Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.537207Z",
          "shell.execute_reply": "2021-06-30T12:51:59.792659Z"
        },
        "trusted": true,
        "id": "vM7GyprC_WAH"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGumGJFQ_WAI"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.796671Z",
          "iopub.execute_input": "2021-06-30T12:51:59.7975Z",
          "iopub.status.idle": "2021-06-30T12:51:59.807852Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.797452Z",
          "shell.execute_reply": "2021-06-30T12:51:59.806689Z"
        },
        "trusted": true,
        "id": "d7X8LGU-_WAJ"
      },
      "source": [
        "class LitDataset(Dataset):\n",
        "    def __init__(self, df, inference_only=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.df = df        \n",
        "        self.inference_only = inference_only\n",
        "        self.text = df.excerpt.tolist()\n",
        "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
        "        \n",
        "        if not self.inference_only:\n",
        "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
        "    \n",
        "        self.encoded = tokenizer.batch_encode_plus(\n",
        "            self.text,\n",
        "            padding = 'max_length',            \n",
        "            max_length = MAX_LEN,\n",
        "            truncation = True,\n",
        "            return_attention_mask=True\n",
        "        )        \n",
        " \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):        \n",
        "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
        "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
        "        \n",
        "        if self.inference_only:\n",
        "            return (input_ids, attention_mask)            \n",
        "        else:\n",
        "            target = self.target[index]\n",
        "            return (input_ids, attention_mask, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNnJX7dS_WAJ"
      },
      "source": [
        "# Model\n",
        "The model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.811306Z",
          "iopub.execute_input": "2021-06-30T12:51:59.811674Z",
          "iopub.status.idle": "2021-06-30T12:51:59.827415Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.811644Z",
          "shell.execute_reply": "2021-06-30T12:51:59.82605Z"
        },
        "trusted": true,
        "id": "WEBk1VIC_WAJ"
      },
      "source": [
        "class LitModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n",
        "        config.update({\"output_hidden_states\":True, \n",
        "                       \"hidden_dropout_prob\": 0.0,\n",
        "                       \"layer_norm_eps\": 1e-7})                       \n",
        "        \n",
        "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
        "            \n",
        "        self.attention = nn.Sequential(            \n",
        "            nn.Linear(768, 512),            \n",
        "            nn.Tanh(),                       \n",
        "            nn.Linear(512, 1),\n",
        "            nn.Softmax(dim=1)\n",
        "        )        \n",
        "\n",
        "        self.regressor = nn.Sequential(                        \n",
        "            nn.Linear(768, 1)                        \n",
        "        )\n",
        "        \n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        roberta_output = self.roberta(input_ids=input_ids,\n",
        "                                      attention_mask=attention_mask)        \n",
        "\n",
        "        # There are a total of 13 layers of hidden states.\n",
        "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
        "        # We take the hidden states from the last Roberta layer.\n",
        "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
        "\n",
        "        # The number of cells is MAX_LEN.\n",
        "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
        "        # In order to condense hidden states of all cells to a context vector,\n",
        "        # we compute a weighted average of the hidden states of all cells.\n",
        "        # We compute the weight of each cell, using the attention neural network.\n",
        "        weights = self.attention(last_layer_hidden_states)\n",
        "                \n",
        "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
        "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
        "        # Now we compute context_vector as the weighted average.\n",
        "        # context_vector.shape is BATCH_SIZE x 768\n",
        "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
        "        \n",
        "        # Now we reduce the context vector to the prediction score.\n",
        "        return self.regressor(context_vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.83115Z",
          "iopub.execute_input": "2021-06-30T12:51:59.831696Z",
          "iopub.status.idle": "2021-06-30T12:51:59.842337Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.831662Z",
          "shell.execute_reply": "2021-06-30T12:51:59.84129Z"
        },
        "trusted": true,
        "id": "Fz3v4EoH_WAK"
      },
      "source": [
        "def eval_mse(model, data_loader):\n",
        "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
        "    model.eval()            \n",
        "    mse_sum = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "            attention_mask = attention_mask.to(DEVICE)                        \n",
        "            target = target.to(DEVICE)           \n",
        "            \n",
        "            pred = model(input_ids, attention_mask)                       \n",
        "\n",
        "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
        "                \n",
        "\n",
        "    return mse_sum / len(data_loader.dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.843942Z",
          "iopub.execute_input": "2021-06-30T12:51:59.844805Z",
          "iopub.status.idle": "2021-06-30T12:51:59.859761Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.844758Z",
          "shell.execute_reply": "2021-06-30T12:51:59.858473Z"
        },
        "trusted": true,
        "id": "zQ6toHww_WAL"
      },
      "source": [
        "def predict(model, data_loader):\n",
        "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    result = np.zeros(len(data_loader.dataset))    \n",
        "    index = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "            attention_mask = attention_mask.to(DEVICE)\n",
        "                        \n",
        "            pred = model(input_ids, attention_mask)                        \n",
        "\n",
        "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
        "            index += pred.shape[0]\n",
        "\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.862869Z",
          "iopub.execute_input": "2021-06-30T12:51:59.863638Z",
          "iopub.status.idle": "2021-06-30T12:51:59.877743Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.863562Z",
          "shell.execute_reply": "2021-06-30T12:51:59.87667Z"
        },
        "trusted": true,
        "id": "wTCAyxiQ_WAL"
      },
      "source": [
        "def train(model, model_path, train_loader, val_loader,\n",
        "          optimizer, scheduler=None, num_epochs=NUM_EPOCHS):    \n",
        "    best_val_rmse = None\n",
        "    best_epoch = 0\n",
        "    step = 0\n",
        "    last_eval_step = 0\n",
        "    eval_period = EVAL_SCHEDULE[0][1]\n",
        "\n",
        "    pred_list = []\n",
        "    target_list = []\n",
        "    pred_lists = []\n",
        "    target_lists = []\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):                           \n",
        "        val_rmse = None         \n",
        "\n",
        "        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n",
        "            input_ids = input_ids.to(DEVICE)\n",
        "            attention_mask = attention_mask.to(DEVICE)            \n",
        "            target = target.to(DEVICE)                        \n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            model.train()\n",
        "\n",
        "            pred = model(input_ids, attention_mask)\n",
        "\n",
        "            # pred_list.append(pred.flatten())\n",
        "            # target_list.append(target)\n",
        "\n",
        "            pred_test = torch.cat([a, b], axis=0)\n",
        "\n",
        "\n",
        "            \n",
        "            # print(\"##########\")\n",
        "            # # print(pred)\n",
        "            # print(\"what is input id??\")\n",
        "            # print(\"Shape \",input_ids.shape)\n",
        "            # print(\"nakami \",input_ids)\n",
        "            # ### stacking用追加\n",
        "            # pd_stack[pd_stack['id'] == input_ids] = pred\n",
        "            # ###\n",
        "            # print(\"#####  Done  #####\")\n",
        "\n",
        "            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n",
        "                        \n",
        "            mse.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "            \n",
        "            if step >= last_eval_step + eval_period:\n",
        "                # Evaluate the model on val_loader.\n",
        "                elapsed_seconds = time.time() - start\n",
        "                num_steps = step - last_eval_step\n",
        "                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
        "                last_eval_step = step\n",
        "                \n",
        "                val_rmse = math.sqrt(eval_mse(model, val_loader))                            \n",
        "\n",
        "                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n",
        "                      f\"val_rmse: {val_rmse:0.4}\")\n",
        "\n",
        "                for rmse, period in EVAL_SCHEDULE:\n",
        "                    if val_rmse >= rmse:\n",
        "                        eval_period = period\n",
        "                        break                               \n",
        "                \n",
        "                if not best_val_rmse or val_rmse < best_val_rmse:                    \n",
        "                    best_val_rmse = val_rmse\n",
        "                    best_epoch = epoch\n",
        "                    torch.save(model.state_dict(), model_path)\n",
        "                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
        "                else:       \n",
        "                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
        "                          f\"(from epoch {best_epoch})\")                                    \n",
        "                    \n",
        "                start = time.time()\n",
        "                                            \n",
        "            step += 1\n",
        "        \n",
        "\n",
        "            # pred_list.append(pred.flatten())\n",
        "            # target_list.append(target_list)\n",
        "\n",
        "        pred_lists.append(pred_list)\n",
        "        target_lists.append(target_list)\n",
        "\n",
        "    hoge = pd.DataFrame()\n",
        "    hoge['pred'] = pred_lists\n",
        "    hoge['target'] = target_lists\n",
        "                        \n",
        "    \n",
        "    return best_val_rmse,pred_lists"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rScwIARFfa4"
      },
      "source": [
        "# pd_stack = train_df.copy()\n",
        "\n",
        "# pd_stack = pd_stack.drop(columns = ['url_legal','license','excerpt','standard_error'])\n",
        "# pd_stack['predict'] = 0\n",
        "\n",
        "\n",
        "# pd_stack[pd_stack['id'] == 'c12129c31'] = 111\n",
        "# pd_stack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev_PhtbrVake"
      },
      "source": [
        "def create_optimizer(model):\n",
        "    named_parameters = list(model.named_parameters())    \n",
        "    \n",
        "    roberta_parameters = named_parameters[:197]    \n",
        "    attention_parameters = named_parameters[199:203]\n",
        "    regressor_parameters = named_parameters[203:]\n",
        "        \n",
        "    attention_group = [params for (name, params) in attention_parameters]\n",
        "    regressor_group = [params for (name, params) in regressor_parameters]\n",
        "\n",
        "    parameters = []\n",
        "    parameters.append({\"params\": attention_group})\n",
        "    parameters.append({\"params\": regressor_group})\n",
        "\n",
        "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
        "        weight_decay = 0.0 if \"bias\" in name else 0.01\n",
        "\n",
        "        lr = 2e-5\n",
        "\n",
        "        if layer_num >= 69:        \n",
        "            lr = 5e-5\n",
        "\n",
        "        if layer_num >= 133:\n",
        "            lr = 1e-4\n",
        "\n",
        "        parameters.append({\"params\": params,\n",
        "                           \"weight_decay\": weight_decay,\n",
        "                           \"lr\": lr})\n",
        "\n",
        "    return AdamW(parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCaqywlIQ5jR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnpgWE4BQ58F",
        "outputId": "5a397a77-1d30-4332-fd37-2f5a43d7f71b"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2833, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T12:51:59.896459Z",
          "iopub.execute_input": "2021-06-30T12:51:59.897025Z",
          "iopub.status.idle": "2021-06-30T13:35:53.917503Z",
          "shell.execute_reply.started": "2021-06-30T12:51:59.896976Z",
          "shell.execute_reply": "2021-06-30T13:35:53.916394Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1QTbKfD_WAN",
        "outputId": "8c1a543a-593d-4cdf-93e9-59a8b4d8c8bb"
      },
      "source": [
        "gc.collect()\n",
        "\n",
        "## stacking 出力用\n",
        "pd_stack = train_df.copy()\n",
        "pd_stack = pd_stack.drop(columns = ['url_legal','license','excerpt','standard_error'])\n",
        "pd_stack['predict'] = 0\n",
        "####\n",
        "\n",
        "hoge = pd.DataFrame()\n",
        "\n",
        "SEED = 1000\n",
        "list_val_rmse = []\n",
        "pred_lists = []\n",
        "\n",
        "# kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
        "kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
        "\n",
        "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n",
        "    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n",
        "    model_path = f\"model_{fold + 1}.pth\"\n",
        "        \n",
        "    set_random_seed(SEED + fold)\n",
        "    \n",
        "    train_dataset = LitDataset(train_df.loc[train_indices])    \n",
        "    val_dataset = LitDataset(train_df.loc[val_indices])    \n",
        "        \n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
        "                              drop_last=True, shuffle=True, num_workers=2)    \n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
        "                            drop_last=False, shuffle=False, num_workers=2)    \n",
        "        \n",
        "    set_random_seed(SEED + fold)    \n",
        "    \n",
        "    model = LitModel().to(DEVICE)\n",
        "    \n",
        "    optimizer = create_optimizer(model)                        \n",
        "    scheduler = get_cosine_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_training_steps=NUM_EPOCHS * len(train_loader),\n",
        "        num_warmup_steps=50)    \n",
        "    \n",
        "    preds,pred_lists = train(model, model_path, train_loader, val_loader, optimizer, scheduler=scheduler)\n",
        "    \n",
        "    list_val_rmse.append(preds)\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "    \n",
        "    print(\"\\nPerformance estimates:\")\n",
        "    print(list_val_rmse)\n",
        "    print(\"Mean:\", np.array(list_val_rmse).mean())\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 6.88 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.8982\n",
            "New best_val_rmse: 0.8982\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.6901\n",
            "New best_val_rmse: 0.6901\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.7285\n",
            "Still best_val_rmse: 0.6901 (from epoch 0)\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6206\n",
            "New best_val_rmse: 0.6206\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.5612\n",
            "New best_val_rmse: 0.5612\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.5853\n",
            "Still best_val_rmse: 0.5612 (from epoch 0)\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.519\n",
            "New best_val_rmse: 0.519\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5158\n",
            "New best_val_rmse: 0.5158\n",
            "\n",
            "Performance estimates:\n",
            "[0.5158341249599311]\n",
            "Mean: 0.5158341249599311\n",
            "\n",
            "Fold 2/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 6.86 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 1.015\n",
            "New best_val_rmse: 1.015\n",
            "\n",
            "16 steps took 6.34 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.7179\n",
            "New best_val_rmse: 0.7179\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.6887\n",
            "New best_val_rmse: 0.6887\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6121\n",
            "New best_val_rmse: 0.6121\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6337\n",
            "Still best_val_rmse: 0.6121 (from epoch 0)\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.542\n",
            "New best_val_rmse: 0.542\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.5414\n",
            "New best_val_rmse: 0.5414\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5203\n",
            "New best_val_rmse: 0.5203\n",
            "\n",
            "Performance estimates:\n",
            "[0.5158341249599311, 0.5202513661652025]\n",
            "Mean: 0.5180427455625668\n",
            "\n",
            "Fold 3/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 6.86 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.9905\n",
            "New best_val_rmse: 0.9905\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.8327\n",
            "New best_val_rmse: 0.8327\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.791\n",
            "New best_val_rmse: 0.791\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6647\n",
            "New best_val_rmse: 0.6647\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.657\n",
            "New best_val_rmse: 0.657\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.583\n",
            "New best_val_rmse: 0.583\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.5804\n",
            "New best_val_rmse: 0.5804\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5458\n",
            "New best_val_rmse: 0.5458\n",
            "\n",
            "Performance estimates:\n",
            "[0.5158341249599311, 0.5202513661652025, 0.5457709919746703]\n",
            "Mean: 0.5272854943666013\n",
            "\n",
            "Fold 4/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 6.86 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 1.085\n",
            "New best_val_rmse: 1.085\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.7577\n",
            "New best_val_rmse: 0.7577\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.6035\n",
            "New best_val_rmse: 0.6035\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6662\n",
            "Still best_val_rmse: 0.6035 (from epoch 0)\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.6299\n",
            "Still best_val_rmse: 0.6035 (from epoch 0)\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.5688\n",
            "New best_val_rmse: 0.5688\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.5643\n",
            "New best_val_rmse: 0.5643\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5345\n",
            "New best_val_rmse: 0.5345\n",
            "\n",
            "Performance estimates:\n",
            "[0.5158341249599311, 0.5202513661652025, 0.5457709919746703, 0.5345460208272431]\n",
            "Mean: 0.5291006259817618\n",
            "\n",
            "Fold 5/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "16 steps took 6.86 seconds\n",
            "Epoch: 0 batch_num: 16 val_rmse: 0.9232\n",
            "New best_val_rmse: 0.9232\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 32 val_rmse: 0.7569\n",
            "New best_val_rmse: 0.7569\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 48 val_rmse: 0.6911\n",
            "New best_val_rmse: 0.6911\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 64 val_rmse: 0.6214\n",
            "New best_val_rmse: 0.6214\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 80 val_rmse: 0.5909\n",
            "New best_val_rmse: 0.5909\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 96 val_rmse: 0.5567\n",
            "New best_val_rmse: 0.5567\n",
            "\n",
            "16 steps took 6.33 seconds\n",
            "Epoch: 0 batch_num: 112 val_rmse: 0.5423\n",
            "New best_val_rmse: 0.5423\n",
            "\n",
            "16 steps took 6.32 seconds\n",
            "Epoch: 0 batch_num: 128 val_rmse: 0.5124\n",
            "New best_val_rmse: 0.5124\n",
            "\n",
            "Performance estimates:\n",
            "[0.5158341249599311, 0.5202513661652025, 0.5457709919746703, 0.5345460208272431, 0.5123893558932818]\n",
            "Mean: 0.5257583719640657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rBBPizbfBnG",
        "outputId": "75b790f8-80be-4b7e-a4e6-cea7c5bb6352"
      },
      "source": [
        "# len(pred_lists[0])\n",
        "\n",
        "[len(v) for v in pred_lists]\n",
        "# pred_lists.shapes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[141]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWRpwquFfEKe",
        "outputId": "51f0c202-2879-4ec3-9028-6a691cde0c0e"
      },
      "source": [
        "aaa = hoge['pred'][0]\n",
        "aaa"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([-0.2975, -0.2553, -0.2861, -0.2735, -0.3167, -0.3550, -0.2259, -0.3057,\n",
              "         -0.3544, -0.3047, -0.2692, -0.2288, -0.2226, -0.2275, -0.2747, -0.2764],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.3647, -0.2856, -0.2904, -0.2996, -0.3314, -0.2874, -0.2392, -0.2823,\n",
              "         -0.2933, -0.2674, -0.2512, -0.3316, -0.2344, -0.2427, -0.3171, -0.2846],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.3424, -0.3121, -0.3118, -0.3148, -0.3647, -0.2723, -0.3455, -0.3420,\n",
              "         -0.3433, -0.3159, -0.2254, -0.2746, -0.2995, -0.3086, -0.3243, -0.3777],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.3713, -0.2858, -0.3152, -0.3297, -0.2515, -0.3494, -0.2898, -0.3975,\n",
              "         -0.4229, -0.4976, -0.3583, -0.3149, -0.3341, -0.4082, -0.3028, -0.3944],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.3624, -0.4318, -0.4142, -0.3841, -0.4036, -0.3909, -0.4430, -0.3281,\n",
              "         -0.4299, -0.3678, -0.3949, -0.3921, -0.4031, -0.4093, -0.3936, -0.4220],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.4709, -0.4950, -0.5112, -0.4726, -0.4877, -0.4977, -0.4349, -0.4587,\n",
              "         -0.4725, -0.5074, -0.4508, -0.4384, -0.4346, -0.4426, -0.3873, -0.4814],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5114, -0.6053, -0.5865, -0.6298, -0.5299, -0.5792, -0.5055, -0.5121,\n",
              "         -0.5082, -0.5623, -0.5153, -0.5766, -0.5404, -0.5173, -0.5329, -0.5873],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.6273, -0.6119, -0.6887, -0.7153, -0.5971, -0.6928, -0.6172, -0.6199,\n",
              "         -0.7150, -0.5764, -0.6926, -0.7118, -0.6746, -0.6553, -0.6589, -0.6256],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.7857, -0.6997, -0.7689, -0.8043, -0.7757, -0.7929, -0.7548, -0.7729,\n",
              "         -0.7440, -0.8934, -0.6842, -0.6133, -0.7479, -0.7682, -0.7680, -0.7884],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.8534, -0.8812, -0.9415, -0.9077, -0.9779, -0.8619, -0.7874, -0.8172,\n",
              "         -0.7887, -0.8740, -1.0361, -0.7921, -0.9441, -0.8634, -0.8338, -0.8766],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.9725, -1.0407, -0.8456, -0.9475, -1.0790, -1.0905, -1.0315, -0.9133,\n",
              "         -0.9476, -1.2292, -1.1444, -0.9016, -0.9383, -1.0198, -1.1520, -1.0301],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.4303, -1.2942, -1.0350, -1.2860, -1.1327, -1.1250, -1.0468, -1.3685,\n",
              "         -1.0810, -1.4255, -1.2621, -1.1103, -1.2299, -1.0660, -0.9588, -1.3293],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.4432, -1.5479, -1.2095, -1.7011, -1.3875, -1.4355, -1.2554, -1.5018,\n",
              "         -1.4734, -1.5395, -1.3100, -1.3138, -1.5576, -1.5964, -1.2315, -1.5743],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.4001, -1.3638, -1.8513, -1.5295, -1.2765, -1.7674, -1.3096, -1.4746,\n",
              "         -1.5710, -1.4502, -1.3380, -1.6778, -1.8818, -1.4437, -1.4567, -1.5316],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.5782, -2.1140, -1.4445, -1.7866, -1.5316, -1.6376, -1.5625, -1.2825,\n",
              "         -1.6549, -1.9177, -1.8085, -1.4542, -1.4457, -1.6516, -1.4667, -1.6805],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.5359, -1.5052, -1.5235, -1.4905, -1.4891, -1.9219, -1.2265, -1.2508,\n",
              "         -1.5654, -1.6942, -1.7626, -1.2435, -1.4507, -1.6019, -1.4607, -1.3813],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1721, -1.5642, -1.1493, -1.0932, -1.3219, -1.4327, -1.1669, -1.6837,\n",
              "         -1.3032, -1.3330, -1.5184, -1.2954, -1.1344, -1.6709, -1.0933, -1.1580],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1299, -1.1497, -0.9002, -1.1225, -0.8970, -1.4538, -0.9826, -1.3363,\n",
              "         -1.2645, -1.0122, -0.8457, -0.9703, -1.2812, -1.0820, -1.0720, -1.2635],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1887, -1.1538, -0.7976, -0.9848, -1.0880, -1.0162, -0.9648, -1.0607,\n",
              "         -1.0560, -0.8408, -1.1109, -0.9465, -0.9890, -0.8651, -0.9194, -1.1664],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.7925, -1.0186, -1.1776, -0.6179, -0.8651, -0.7576, -0.9370, -0.8069,\n",
              "         -0.8206, -0.6669, -0.9473, -0.8508, -0.9743, -0.9153, -0.8476, -1.0787],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.6841, -0.7592, -0.5837, -0.5632, -0.6449, -0.7895, -0.6300, -0.7646,\n",
              "         -0.9705, -0.4783, -0.7287, -0.7425, -1.0328, -0.8585, -0.7551, -0.6019],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5458, -0.7232, -0.7259, -0.6001, -0.8319, -0.9667, -0.9576, -1.0869,\n",
              "         -0.6379, -0.8336, -1.0108, -0.5709, -0.7321, -1.0257, -0.7752, -1.1644],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.7472, -0.8091, -0.8817, -0.7372, -0.5857, -0.7266, -0.4295, -0.7217,\n",
              "         -0.8049, -0.6391, -0.8645, -0.8673, -0.5314, -0.9235, -0.7869, -0.8491],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.9512, -0.9971, -0.8535, -0.6415, -0.7038, -0.5936, -0.5976, -0.7163,\n",
              "         -0.7825, -0.6347, -0.4368, -0.9170, -0.7550, -0.5407, -0.6975, -0.5465],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.6292, -0.8113, -0.7186, -0.8451, -0.7879, -1.2474, -0.6259, -1.2983,\n",
              "         -0.7457, -0.9830, -0.7571, -0.4216, -1.2935, -1.1678, -0.6746, -0.7836],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.4705, -0.9798, -0.7152, -0.9304, -0.5385, -0.2754, -1.0143, -0.6861,\n",
              "         -1.4324, -0.4319, -0.5063, -0.8920, -1.1043, -1.5580, -0.8147, -0.3998],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.8557, -1.3570, -0.3093, -0.4154, -1.0797, -0.7813, -0.7914, -1.8469,\n",
              "         -1.5703, -0.5232, -1.3150, -1.7682, -0.6013, -1.7527, -0.6168, -0.5608],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5619, -1.7978, -0.8530, -1.7562, -0.7154, -0.9850, -2.3936, -1.8211,\n",
              "         -0.8174, -0.8290, -1.0595, -1.2657, -0.5994, -2.3265, -1.6783, -0.5812],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.6908, -1.1354, -0.5984, -1.9736, -1.2111, -1.7809, -0.7375, -0.4360,\n",
              "         -1.1545, -2.3064, -1.3587, -0.3920, -0.8729, -0.9910, -1.6868, -1.9180],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.4004, -1.5720, -0.3622, -1.4533, -1.6660, -0.6563, -1.0040, -1.2196,\n",
              "         -1.3430, -0.3691, -1.9823, -0.3363, -1.2568, -1.1766, -0.6949, -0.7962],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.2266, -1.5833, -1.3250, -0.5351, -0.8968, -0.5032, -1.7005, -1.0744,\n",
              "         -1.5821, -0.0856, -0.3956, -0.5492, -1.1829, -0.7447, -0.3252, -0.4675],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.6263, -1.2306,  0.1119,  0.1359, -2.1070, -0.5363,  0.2292, -0.4392,\n",
              "          0.0233, -0.2764,  0.4438, -1.6806, -1.4093, -0.1692, -0.4613, -0.7229],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5309, -0.9308, -0.1580,  0.0709, -0.7963, -0.8507, -0.6430, -0.3177,\n",
              "         -0.4273, -0.8827, -1.2380, -1.2368, -0.0294, -0.2725, -0.6651,  0.2563],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.1542, -1.9741, -0.8740, -1.4887, -0.3471,  0.1592, -2.6101, -0.0433,\n",
              "         -1.8641,  0.3801, -1.5874, -1.8567, -1.0272, -0.1520, -2.1348,  0.0070],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1922, -0.5851, -0.0123, -1.8518, -0.5258, -1.8818, -1.3196,  0.1526,\n",
              "         -1.3401,  0.5702, -1.0928, -1.7367, -0.6068, -1.2823, -1.4375, -2.3271],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.3358, -1.1940, -2.4102, -2.4866, -1.1292, -1.3274, -1.3183, -1.3382,\n",
              "         -0.0622, -0.0731, -0.8085, -3.6152, -1.3398,  0.3477,  0.2084, -3.6223],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.8744, -1.8617, -1.1644, -3.7644,  0.1613, -2.3720, -1.3701, -1.7082,\n",
              "         -1.3123, -3.1665, -2.8650,  0.1469, -0.9706, -3.5136, -2.5286, -3.5263],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.0183, -2.2044, -0.5733, -2.2857, -0.1003, -0.5027, -0.0185, -0.4572,\n",
              "         -0.8114, -1.8957, -1.4858, -3.1098, -1.0468, -0.7445, -1.8012, -0.6969],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.1634, -1.2038, -0.6761, -2.5742, -2.0239, -0.0661, -0.4591, -1.4588,\n",
              "         -0.9919, -0.1702, -0.3556, -0.7631,  0.1718, -1.2145, -1.2948, -0.5023],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5149, -0.7174, -0.2650, -1.5583,  0.0930, -0.1322, -0.1543, -1.0961,\n",
              "         -0.4832, -1.6529, -0.4344, -0.2168, -1.1382,  0.0448, -0.9614, -1.7648],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.2291,  0.0097, -0.5025,  0.1260, -1.0848, -0.7182, -1.5931, -0.6482,\n",
              "         -0.2217, -0.4852, -0.8604, -1.4497, -0.1093, -0.8205, -0.9003, -0.5029],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.7036, -0.5937, -0.8621, -1.0221, -0.5066, -0.2756, -0.6774, -0.1973,\n",
              "         -1.3343, -0.8941, -0.7618, -0.0219, -0.9967, -1.4703, -0.9885, -0.1734],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.0479, -1.3788, -1.4851, -0.9935, -0.8371, -1.5789, -0.6624, -0.6043,\n",
              "         -0.8336, -1.1110, -0.7822, -1.1118, -1.3188, -1.2402, -0.0990, -0.8504],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.8653, -0.4360, -1.0926, -0.5507, -0.5274, -1.5718, -1.4616, -0.1716,\n",
              "         -1.5849, -1.4280, -1.2482, -1.1047, -1.2443, -0.6134, -1.4882, -0.9636],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.3575, -0.9509, -0.9550, -0.7932, -1.0870, -0.7004, -1.2608, -1.3907,\n",
              "         -0.7410, -1.0448, -1.1401,  0.1479, -0.8287, -0.4864, -1.4986, -1.7266],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.3442, -1.4016, -1.8069, -0.7423, -1.5546, -1.6577, -1.7699, -1.4515,\n",
              "         -0.5950, -1.2934, -1.4707, -1.2084, -0.9980, -1.3356, -1.0371, -0.9299],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.7757, -1.1261, -0.5329, -1.6574, -0.4526, -0.9156, -0.6971, -1.8383,\n",
              "         -1.7799, -1.4140, -1.3981, -1.1369, -0.7155, -0.8377, -1.0925, -1.0856],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.5238, -1.1287, -1.3737, -1.3170, -1.0508, -0.6804, -1.2408, -1.4083,\n",
              "         -1.7108, -1.3637, -0.0048, -0.1499, -1.2329, -1.0094, -0.7320, -0.5035],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.9465, -0.4633, -0.6008, -1.4728, -1.0387, -1.0474, -1.6686, -0.9470,\n",
              "         -0.3232,  0.1816, -1.8510, -1.2964, -1.6903, -0.1530, -0.7946,  0.0458],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.8748, -0.9673, -0.8429, -0.3255, -1.2294, -1.8426, -0.8244, -1.9762,\n",
              "         -0.8339, -0.9319, -0.6002, -1.3536, -1.2276, -1.6849, -0.8806, -1.3722],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.6630, -0.7870, -0.9671, -0.1503, -1.0792, -0.5929, -1.4493, -0.8710,\n",
              "         -0.3017, -0.0197, -0.9068, -0.3673, -0.7974, -1.7868, -1.6083, -0.3409],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.2796, -1.2546, -0.3882, -1.0567,  0.6894, -1.2943, -0.6193, -0.1000,\n",
              "          0.5294, -0.8479, -2.1070, -0.9951,  0.9417, -2.3022, -2.1872, -1.8550],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.0137, -0.8413, -0.4996, -2.0902, -1.5593,  0.5229, -1.7357, -0.1866,\n",
              "          1.0618, -2.0327, -2.5436, -0.3288,  0.2342, -1.5707, -1.5466,  0.1581],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.7398, -2.0420, -1.0223, -2.2230, -2.6917, -1.9410, -1.8649, -2.5684,\n",
              "         -1.8534, -2.5962, -0.2263, -1.3596, -1.7329, -1.4819, -1.6201, -0.7623],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.8214, -1.5359, -1.9009, -0.8912, -1.5359, -2.3137,  0.4627, -2.5670,\n",
              "         -2.1689, -1.5134, -0.4026, -2.0679, -1.3019, -0.7961, -1.6347, -0.8769],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.4242, -1.8075, -1.0592, -2.1922, -0.0586, -1.4359, -1.6412, -0.5578,\n",
              "         -1.4552, -1.9959, -0.4155, -1.9201, -0.9205, -1.3400, -0.4945, -0.4283],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.9812, -1.8975, -1.1682, -1.2921,  0.4654, -0.7456, -1.6842, -0.3459,\n",
              "         -0.6124, -0.9919, -0.8096, -1.0469, -0.5605, -0.6434, -0.5830, -0.3239],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.1998, -1.4470, -1.1003,  0.2173, -0.9886, -0.2540, -1.8150,  0.2976,\n",
              "         -1.0001, -0.9620, -0.0664, -1.1530, -1.7813, -0.4274, -1.7325, -1.8938],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.2860, -0.9851,  0.1262, -0.3960, -0.7592, -2.0329, -1.3122, -0.7372,\n",
              "         -0.5913, -1.2552, -0.4994, -0.2403,  0.0050, -0.1301, -0.1770, -1.2440],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.4334, -0.4677, -1.3995, -1.4594, -0.7625, -1.1154, -2.0050, -1.0449,\n",
              "         -2.1801, -0.5065, -1.6055,  0.0522, -1.0102, -1.9124,  0.0831, -1.5800],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5223, -0.7093,  0.0031, -0.7730, -1.4801, -1.0753, -1.4241,  0.2300,\n",
              "         -0.7488, -1.0894, -0.5962, -1.4958,  0.1136, -1.9706, -0.5239,  0.0859],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.0719, -0.0479, -0.0244, -0.4478,  0.0935, -1.9548, -0.5628, -0.8014,\n",
              "         -1.1806, -0.6753, -0.8627,  0.1804,  0.2007, -1.3321,  0.0723, -1.0511],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1496, -1.4202, -0.8320, -0.9558, -1.1996, -0.5902, -1.0113, -1.3568,\n",
              "         -0.1235, -1.7140, -0.8777, -0.4235, -0.8651, -1.8760, -1.5543, -1.6708],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.4868, -1.9073,  0.4204, -2.1019, -0.8676, -1.4470, -1.3320, -0.3210,\n",
              "         -0.5944,  0.0797, -1.4319, -0.7231, -0.4487,  0.4163,  0.2201, -2.4077],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.2691, -2.1752, -0.5476, -0.4064, -1.4692,  0.3619, -1.2259, -0.2880,\n",
              "         -0.8538, -1.1554, -1.4159, -0.8410,  0.3152, -1.5242, -1.2592, -2.2178],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.4658, -1.1148,  0.4922, -1.4393, -1.7231, -0.1196, -1.1432, -0.8793,\n",
              "          0.2132, -0.0727, -0.7892,  0.6899, -2.2419, -0.9159, -2.2883,  0.5339],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.9287, -0.2252, -0.8346, -2.0406,  0.3258, -1.7342,  0.5785, -0.7485,\n",
              "          0.0863, -1.6204,  0.2829, -2.2410,  0.1510, -0.8992,  0.8108,  0.4744],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.1703, -1.7680, -0.1156,  0.6605, -2.3199, -1.2032, -2.0907, -1.6574,\n",
              "          0.3718, -1.3387, -0.3430, -1.2745, -0.5575, -0.5347, -0.1522, -1.0236],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.3731, -0.2225, -0.5576,  0.1912, -1.3744, -2.3502, -1.4581, -1.3996,\n",
              "         -2.0236, -2.1024, -0.9334, -0.3892,  0.1040, -0.4286, -2.6276, -2.0526],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.3845, -0.3392, -2.1756, -0.3945, -2.0668,  0.0544, -0.0953,  0.1713,\n",
              "         -0.4627, -0.4111,  0.1212, -0.4503, -2.0710, -0.1656, -2.5846, -2.3627],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.3476, -0.8587, -1.2024, -1.1300, -0.0418, -0.3596, -0.7157, -1.4139,\n",
              "         -2.6046, -2.8632, -0.6918, -1.2299, -2.3740, -2.2502, -1.6034, -0.9334],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.8928, -1.1247, -0.4059, -0.1324, -2.7162, -0.9741, -0.9839, -2.3351,\n",
              "         -1.1395, -1.7845, -2.6555, -0.8448, -1.1853, -2.4818, -2.7978, -2.6454],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.3850, -1.8001, -2.0565, -2.1412, -0.8436, -0.2455,  0.0505, -0.0700,\n",
              "         -0.8807,  0.2833, -0.6865, -2.0590, -1.1355, -2.6972, -1.2815, -1.5826],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.3289,  0.2144, -2.4622, -0.4702, -1.4296, -0.0930, -1.1691, -0.2067,\n",
              "         -2.2209, -2.1275, -1.6061, -2.1199,  0.2462, -2.6131, -0.8635, -0.6841],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.5406,  0.4530, -1.9495, -2.3964, -1.1804, -1.3543, -0.8831,  0.3487,\n",
              "         -0.8010, -0.7517,  0.3761, -0.2661,  0.3284,  0.3776, -0.6570, -2.2293],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.6060, -1.7795, -2.0685, -0.3120, -2.4762, -1.0467,  0.2002, -2.6205,\n",
              "          0.5291,  0.3221, -0.5248,  0.1659, -2.5531, -1.0683, -2.4387, -1.1204],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.0790,  0.3090, -0.5010, -0.1920, -0.5953,  0.3123,  0.4480, -2.0257,\n",
              "         -1.3385, -0.6155, -2.5772, -1.3185, -0.0296, -1.1923,  0.0635, -0.8445],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.1192,  0.2598, -1.8464,  0.3177, -2.4710, -1.8079,  0.2686, -2.4615,\n",
              "         -0.3711, -1.5035, -1.7517, -1.4669,  0.0557, -0.1453, -1.3439, -1.8342],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1962e+00,  3.8990e-02, -7.6542e-01,  2.0816e-03, -1.9496e+00,\n",
              "         -1.2120e-01,  1.9907e-01, -1.6461e+00, -1.1555e+00, -1.3485e-01,\n",
              "         -2.3789e+00, -2.7858e+00, -1.2699e+00, -7.7974e-01, -1.4097e-01,\n",
              "         -3.0220e+00], device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.0774,  0.2763, -1.2944,  0.0112, -1.9591, -2.5100, -1.0581, -1.8858,\n",
              "         -0.7567, -2.5526, -0.6043, -0.2339, -2.7077, -0.7424, -0.2891, -1.9373],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.7291, -0.7953, -0.6787, -2.4063, -0.7594, -0.8026, -1.3416, -1.4410,\n",
              "         -2.3334, -1.2294, -2.2903, -1.9337, -0.4858, -0.6169, -0.2391, -1.9821],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-3.1715, -1.9279, -0.2137, -1.3381, -2.7227, -0.9388, -2.2280, -2.3574,\n",
              "         -2.3419, -0.9555, -2.5584, -2.4002, -0.1170, -2.6283,  0.1303,  0.1896],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.4176, -0.6331,  0.2693, -1.0184, -0.1471, -0.5991, -0.9587,  0.3856,\n",
              "         -0.7001,  0.2015, -2.2904, -0.1085, -0.1750, -1.6218, -2.2160, -1.2588],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5650, -1.0353, -0.2125, -0.9887, -0.0596, -0.8195, -0.7433, -0.0108,\n",
              "         -0.9201, -1.6558,  0.3740, -1.5117, -2.7898, -0.3901,  0.6416,  0.1223],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.4077, -2.7332,  0.1427, -1.3894, -2.0857, -1.4302, -2.1222, -1.3694,\n",
              "         -1.6038,  0.2972, -2.5493, -2.2994, -0.1702, -2.1905, -0.2687, -0.7890],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.2849, -0.1326,  0.0070, -1.8738, -0.4421, -0.6438,  0.0636, -1.4282,\n",
              "          0.2774, -0.3401, -0.1452, -2.4109, -2.1189, -0.2102,  0.0271, -0.8029],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.3564, -1.1529, -0.3277, -0.0651, -0.4079, -1.1491, -0.8159, -0.0070,\n",
              "         -1.3448, -0.3351, -2.1792,  0.0234,  0.3576,  0.1991, -2.6903, -1.3249],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.5614, -0.1316, -0.5733, -1.7744, -2.0964, -0.1448, -2.0113, -0.8181,\n",
              "         -0.3524, -0.6590, -1.3914, -0.3053, -0.6988, -1.7972, -1.4724, -2.1463],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.0360, -1.3977, -0.4342, -2.2251, -0.1205, -1.5056, -0.5308, -0.7298,\n",
              "         -0.3001, -2.2831, -1.1940, -0.4249, -0.8945, -0.6002, -0.7131, -0.5292],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1919, -1.6992, -2.1764, -2.0228, -0.3757, -2.1406, -0.7073, -0.0617,\n",
              "         -1.6486, -0.5532, -1.2026, -0.9630, -1.7124, -1.0412, -0.0945, -2.3390],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5536,  0.1770, -1.2058, -2.6010, -1.2598, -1.2571, -2.3971, -0.8042,\n",
              "         -2.1741, -0.0559, -2.2575, -1.3911, -0.1482, -1.4147, -2.0271, -1.6991],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.3989, -0.9247, -1.8815, -0.6359, -1.7619,  0.0564, -0.9296, -0.9983,\n",
              "         -0.8492, -2.1294, -2.1654, -2.5468, -1.2338, -0.3624, -2.2190, -2.0211],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.2009, -0.6855, -0.8922, -0.8466, -1.0856, -1.4288, -0.8963, -1.5013,\n",
              "         -1.7848, -2.0137, -1.5811, -1.6205, -1.1178, -1.0017, -2.9295, -0.3158],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.3786, -0.7000, -0.4235, -0.7475, -0.4227, -0.6029, -2.1898, -2.4211,\n",
              "         -1.3083, -0.9054, -0.8299, -1.3243, -0.8011, -0.6176, -2.0871, -1.2897],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5651, -0.0627,  0.2717, -1.1137, -0.7447, -2.1098, -1.3360, -1.9035,\n",
              "         -1.4658, -0.7430, -1.1450, -1.6121, -1.2935,  0.0769, -0.7975, -1.1816],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.1345, -1.0575, -1.0877, -1.1275, -0.5312, -0.4537, -1.7060,  0.0671,\n",
              "         -0.0107, -1.4147, -0.5560, -0.5225, -1.5621, -1.7998, -2.7175,  0.2326],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.7637, -1.0372, -0.4997, -0.2463, -2.2977, -0.5459, -0.9156, -0.9552,\n",
              "         -0.6052, -0.2090, -1.4564, -1.0979, -1.3874, -0.9049, -1.5189, -0.0915],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.0300, -1.7971, -0.2156,  0.1445, -1.9546, -0.6106, -1.6867, -1.4129,\n",
              "         -0.6942, -1.0613, -0.6249, -0.7437, -1.3425, -0.3996, -0.1328, -1.2440],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.9490, -0.6593,  0.4542, -0.0641, -1.0549, -0.4641, -0.3408, -0.0991,\n",
              "         -2.5713, -0.3603, -2.5383, -1.4118, -2.4933, -0.0563, -0.4310,  0.2742],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5538, -2.2074, -1.4422, -0.2543, -0.0695,  0.3178,  0.0214, -1.1557,\n",
              "         -0.3894,  0.1797, -0.8828,  0.0745,  0.2712, -0.4809, -1.9916,  0.2677],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.2501, -0.8172,  0.4206, -0.9584,  0.1621, -1.1562, -1.6509, -0.2298,\n",
              "         -2.2694,  0.0112, -1.1495, -1.7643,  0.4689, -0.8912, -1.8215, -2.1557],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1278, -1.5307,  0.2551, -1.0966,  0.4024, -1.5065, -0.4177,  0.3085,\n",
              "         -0.6779, -2.2532, -1.8715,  0.3919,  0.5187,  0.3181, -0.5850,  0.3581],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.1811, -2.7100, -1.7804, -0.9754, -1.3168, -1.3113,  0.5609,  0.4883,\n",
              "         -1.4931, -1.5093, -0.3801,  0.1261,  0.4238, -0.9934, -0.0777, -1.8713],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.3872,  0.2307, -1.3014, -0.7483, -0.6070, -1.0956,  0.1449,  0.4285,\n",
              "          0.2002, -0.8436, -0.7739, -2.6743, -1.1735,  0.1274, -0.8125, -0.8871],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.3757,  0.5179,  0.2024, -0.9786,  0.0976, -2.1213, -2.1152, -0.5675,\n",
              "         -2.5985,  0.0435, -1.7118, -2.4797, -0.6924, -1.6990, -0.3250, -1.8083],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.3551,  0.0832, -0.3552, -0.2941, -2.5330, -1.8944, -2.6265,  0.0411,\n",
              "         -1.3472, -1.1922,  0.4330, -1.4931, -2.4639,  0.1368, -0.6934, -0.1789],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.7417, -2.7889, -2.9533, -2.0782, -0.1225, -1.7755, -1.2610, -2.5205,\n",
              "         -2.1542, -1.6128, -1.1600, -0.6604, -0.4208, -0.7191, -1.1996, -0.1590],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.1606, -2.3827, -1.1541, -0.7667, -0.5683, -1.9797, -0.1267, -1.8177,\n",
              "         -0.9996, -2.4367, -0.4350,  0.3833, -0.6510, -1.1081, -0.2895, -2.0155],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.4072, -1.7465,  0.0706, -2.4285,  0.1657, -1.7940, -2.2628, -1.1494,\n",
              "          0.3517, -2.0925, -0.5473, -0.3950, -0.1525, -2.6210,  0.1667, -0.7963],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.0882, -1.6903,  0.1881, -1.2769, -1.1070, -2.2302, -0.0547, -0.6921,\n",
              "         -0.4726, -0.7026,  0.5254, -0.1185, -0.7171, -0.4491, -0.9571,  0.6504],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.8299,  0.0041,  0.0087,  0.3056, -1.0940,  0.1274, -1.4629, -0.1280,\n",
              "         -1.1029, -1.0888, -2.6941,  0.2436, -0.8105,  0.3966, -2.0923, -1.7760],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.8527, -2.1639, -0.1631,  0.5963, -1.9260,  0.4636, -2.2504, -1.3258,\n",
              "         -1.1714, -2.4286, -0.1190,  0.9145, -2.0354, -2.0804, -2.2748, -0.1028],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.4855,  0.0714, -2.1182, -1.2764, -0.1107, -2.0032, -1.1913, -0.7697,\n",
              "         -0.2501, -2.2574, -1.8048, -0.6847, -1.5461,  0.2893, -1.0667, -1.6264],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.7090, -0.0425, -1.1296,  0.4639, -2.0323, -1.8398, -0.5586, -2.7629,\n",
              "         -0.7659, -0.5999, -1.4914, -0.9021, -2.4300, -1.8096, -2.2269, -1.7374],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.0624,  0.7068, -0.3698,  0.3731,  0.3266,  0.2781,  0.1484, -0.4914,\n",
              "         -1.7032, -1.9697, -1.8689, -1.3563, -0.3288, -0.4600, -0.8158, -1.5867],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.7996, -0.5026, -0.6730, -0.8632, -2.0006, -1.6799, -0.5312, -0.8201,\n",
              "         -2.0636, -1.2180, -2.2942,  0.0491, -2.5636,  0.2442,  0.6757, -1.6874],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 1.0418, -0.3359,  0.1620, -2.3157, -1.6534, -1.8148, -0.7538, -1.2280,\n",
              "          0.5954, -1.9780,  0.1431,  0.0317, -0.2787, -2.0231, -0.0614,  0.3086],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.2776, -0.9737, -1.3669, -0.9295, -2.1169, -0.0281, -2.4537, -0.0191,\n",
              "         -1.4509, -0.9949, -0.0522, -1.3913, -0.2800, -0.2808, -0.8254, -0.9937],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.2022, -2.5485,  0.4231, -1.5176, -0.7381, -0.5635, -1.6840, -0.1997,\n",
              "         -1.0572, -0.6441, -2.3044, -0.2558, -1.8963, -0.5166, -1.3953,  0.0838],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.0375, -0.2336,  0.4813, -2.3312, -0.6001,  0.3479, -1.6302, -0.0606,\n",
              "         -0.2134,  0.5457, -1.3294,  0.8540, -0.4639, -0.7863,  0.2234, -0.9495],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.7621,  0.2103, -2.0463, -0.1718, -1.6360, -2.4975, -0.9145,  0.2913,\n",
              "         -0.1276, -1.1678, -1.1261,  0.3779,  0.3755, -0.3277,  0.1800, -0.9263],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5183,  0.1543, -0.8302, -0.3042, -0.6420, -0.3373, -0.1967, -1.6722,\n",
              "         -0.4558, -0.6530, -2.0925, -1.1230, -1.1346, -1.3768, -2.4246, -2.3754],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.2663, -2.6179,  0.1777,  0.1817, -0.1373,  0.4900, -1.0532, -0.5542,\n",
              "         -2.2343,  0.6123, -1.9266, -0.3631,  0.3786,  0.5619, -1.6402, -0.2954],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.0396,  0.1459,  0.3668, -0.8412, -1.8186,  0.1478, -0.6611, -1.0656,\n",
              "         -2.0366, -0.9397, -0.5947, -1.7984,  0.6917, -0.9125, -1.9237, -1.2413],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.7387, -1.2716, -0.4169,  0.2349, -0.6562, -1.6726, -0.1769, -1.8846,\n",
              "         -0.4079, -2.2066,  0.5772, -2.0036, -0.1370, -0.4437, -0.7929, -1.0903],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.8699,  0.4538, -1.3380, -1.2913, -0.9017, -1.5516,  0.4847, -2.7930,\n",
              "          0.1043, -2.0846, -0.7934, -2.8445, -1.9916, -1.8243,  0.0668, -1.7142],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.6300, -2.3512, -0.0503, -1.0936, -0.4390, -0.6507, -1.9046,  0.2946,\n",
              "         -0.2365, -0.3072, -0.1931, -1.2803, -1.6472, -0.0763, -2.5465, -1.3926],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.7586, -1.3428, -1.6256, -0.0256, -1.4960, -1.7174,  0.5443, -1.0346,\n",
              "          0.0589, -1.5455,  0.3654,  0.6147, -0.7704,  0.3539, -0.2411, -0.2530],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.2307,  0.0978,  0.7506, -1.8304, -2.4077, -0.9801, -0.4998, -1.4512,\n",
              "         -0.7189, -0.3379,  0.2081,  0.3858, -0.1427, -0.9343,  0.1103,  0.3189],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-2.0260,  0.2700, -0.6148,  0.1934, -0.5738,  0.3788, -0.5844, -0.6729,\n",
              "         -1.6718, -0.0612, -0.1514,  0.0069,  0.3234, -0.4635,  0.2686, -1.7911],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.1578, -2.1026, -2.0400,  0.1179, -0.4996, -2.0188, -0.7952, -1.3179,\n",
              "          0.2086, -0.9213, -0.3620,  0.1272, -0.5711, -0.2038, -2.0476, -0.8206],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.1582, -2.1731,  0.2198,  0.1393, -1.3959, -2.2719, -1.3999, -1.8144,\n",
              "          0.1650, -0.3792, -2.5331, -0.7388, -0.2563, -0.0872, -0.0849,  0.4905],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.5328, -2.0608, -1.2077, -0.5896, -0.8822, -1.0531, -1.0988, -2.4750,\n",
              "         -0.0846, -0.6631, -2.1745, -0.6784, -1.0662, -1.2624, -1.0481,  0.5083],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.0468, -0.5544, -0.6329, -1.8812,  0.1838, -0.1410,  0.3820, -0.8105,\n",
              "         -1.7887, -2.3714, -1.3161, -0.8154,  0.0445, -1.3040, -1.0712, -1.3437],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.2761, -1.9789,  0.4432, -0.2414, -1.0892, -0.3994, -2.0965, -1.1714,\n",
              "         -0.2071, -1.8978,  0.0874, -1.3682, -0.0075, -1.9731,  0.0348, -0.5714],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([ 0.7511, -2.0143, -0.6581, -1.7347, -2.2587, -2.2763, -2.3113, -0.2571,\n",
              "          0.4884, -1.5798, -0.7014, -1.3373, -0.3779, -0.9605, -0.0033, -0.6221],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.5393, -0.3596, -0.9640,  0.3840, -0.2249, -0.4217, -1.3019,  0.1483,\n",
              "          0.1468, -1.3754, -0.9683, -0.3403, -0.8262, -2.5554, -0.3582, -2.0408],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.4497, -0.8591, -1.3172, -1.1452, -2.3928, -0.2826,  0.3484,  0.5561,\n",
              "         -1.8381,  0.5025, -0.7135,  0.3096, -2.7696,  0.2767, -1.9856, -1.3451],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-1.2041,  0.0096, -0.6705,  0.3782, -2.5450,  0.2686, -1.4308, -1.8180,\n",
              "         -1.0216, -2.0578, -1.3310, -1.0506, -2.3664, -1.7858, -1.2084, -0.5374],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.6957,  0.4235, -0.1309, -1.7114, -2.4686, -1.8732, -1.4500,  0.0291,\n",
              "         -0.8575, -1.4648, -1.0149, -0.8618, -0.0835, -0.1772,  0.5872,  0.3600],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>),\n",
              " tensor([-0.5311,  0.1851,  0.3845, -2.2901, -0.6786, -0.5785,  0.0867, -0.1916,\n",
              "          0.6128, -0.3163,  0.5041, -0.4398,  0.1689,  0.1905,  0.1194,  0.1413],\n",
              "        device='cuda:0', grad_fn=<ViewBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulDkZFgg4jEB",
        "outputId": "6a0793be-b198-49e1-b4e6-6847197c851f"
      },
      "source": [
        "hoge.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(141, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqO89_x78LFe",
        "outputId": "fa025007-b0fa-4e74-e26d-a01a39d8b804"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2833, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2XvhD_a8LDF",
        "outputId": "51c210f4-d07d-43e5-fa58-66bd7a108fba"
      },
      "source": [
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5123893558932818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfXf1gEh_WAO"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZuyEAld_WAO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:38:15.716353Z",
          "iopub.execute_input": "2021-06-30T13:38:15.716814Z",
          "iopub.status.idle": "2021-06-30T13:38:15.732351Z",
          "shell.execute_reply.started": "2021-06-30T13:38:15.716779Z",
          "shell.execute_reply": "2021-06-30T13:38:15.730897Z"
        },
        "trusted": true,
        "id": "7zO4Ua_t_WAO"
      },
      "source": [
        "test_dataset = LitDataset(test_df, inference_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:38:15.946699Z",
          "iopub.execute_input": "2021-06-30T13:38:15.947161Z",
          "iopub.status.idle": "2021-06-30T13:38:44.766338Z",
          "shell.execute_reply.started": "2021-06-30T13:38:15.947132Z",
          "shell.execute_reply": "2021-06-30T13:38:44.765073Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF0XYwX3_WAO",
        "outputId": "c5864dda-2db0-4739-da80-936b31f7df9b"
      },
      "source": [
        "all_predictions = np.zeros((len(list_val_rmse), len(test_df)))\n",
        "\n",
        "test_dataset = LitDataset(test_df, inference_only=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                         drop_last=False, shuffle=False, num_workers=2)\n",
        "\n",
        "for index in range(len(list_val_rmse)):            \n",
        "    model_path = f\"/content/drive/MyDrive/CommonLit/output/pre-trained-roberta-solution-in-pytorch/model_{index + 1}.pth\"\n",
        "    print(f\"\\nUsing {model_path}\")\n",
        "                        \n",
        "    model = LitModel()\n",
        "    model.load_state_dict(torch.load(model_path))    \n",
        "    model.to(DEVICE)\n",
        "    \n",
        "    all_predictions[index] = predict(model, test_loader)\n",
        "    \n",
        "    del model\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using /content/drive/MyDrive/CommonLit/output/pre-trained-roberta-solution-in-pytorch/model_1.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using /content/drive/MyDrive/CommonLit/output/pre-trained-roberta-solution-in-pytorch/model_2.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using /content/drive/MyDrive/CommonLit/output/pre-trained-roberta-solution-in-pytorch/model_3.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using /content/drive/MyDrive/CommonLit/output/pre-trained-roberta-solution-in-pytorch/model_4.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using /content/drive/MyDrive/CommonLit/output/pre-trained-roberta-solution-in-pytorch/model_5.pth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at /content/drive/MyDrive/CommonLit/input/commonlitreadabilityprize/clrp-roberta-base/clrp_roberta_base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:38:44.768432Z",
          "iopub.execute_input": "2021-06-30T13:38:44.76888Z",
          "iopub.status.idle": "2021-06-30T13:38:46.049004Z",
          "shell.execute_reply.started": "2021-06-30T13:38:44.768847Z",
          "shell.execute_reply": "2021-06-30T13:38:46.047925Z"
        },
        "trusted": true,
        "id": "0y5fTlUv_WAP"
      },
      "source": [
        "predictions = all_predictions.mean(axis=0)\n",
        "submission_df.target = predictions\n",
        "print(submission_df)\n",
        "submission_df.to_csv(\"/content/drive/MyDrive/CommonLit/output/pre-trained-roberta-solution-in-pytorch/submission.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXL8w9xC_WAP",
        "outputId": "021b1b84-9adf-4ab8-f95a-cb631f50024d"
      },
      "source": [
        "all_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4110876 , -0.74669015, -0.40717465, -2.30235672, -1.78312433,\n",
              "        -1.41173363,  0.23158659],\n",
              "       [-0.32000226, -0.51885808, -0.2224544 , -2.41730547, -1.62717474,\n",
              "        -1.00956726,  0.30301461],\n",
              "       [-0.52017486, -0.5785206 , -0.33318728, -2.56297708, -1.76609135,\n",
              "        -1.57540727,  0.17660873],\n",
              "       [-0.52818757, -0.60989404, -0.32330498, -2.55047774, -1.77477276,\n",
              "        -1.29904222,  0.28325811],\n",
              "       [-0.41792297, -0.70612031, -0.42490819, -2.6773386 , -1.92220187,\n",
              "        -1.48353493,  0.19137977]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}