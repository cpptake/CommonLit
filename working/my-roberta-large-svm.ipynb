{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip uninstall fsspec -y\n# !pip install --upgrade fsspec\n# !pip install transformers accelerate datasets","metadata":{"_uuid":"15c381cd-2a31-4ed7-8d5c-658a46471a46","_cell_guid":"0370cb58-b86e-4c5e-818e-02d66259e073","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-29T05:34:23.910598Z","iopub.execute_input":"2021-07-29T05:34:23.911039Z","iopub.status.idle":"2021-07-29T05:34:23.915804Z","shell.execute_reply.started":"2021-07-29T05:34:23.910944Z","shell.execute_reply":"2021-07-29T05:34:23.914538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport random\nimport time\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AdamW\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom transformers import AutoConfig\nfrom transformers import get_cosine_schedule_with_warmup\n\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\nimport gc\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:13.519199Z","iopub.execute_input":"2021-08-02T13:38:13.519626Z","iopub.status.idle":"2021-08-02T13:38:24.254274Z","shell.execute_reply.started":"2021-08-02T13:38:13.519541Z","shell.execute_reply":"2021-08-02T13:38:24.253246Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# test_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n# submission_df = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.256196Z","iopub.execute_input":"2021-08-02T13:38:24.256593Z","iopub.status.idle":"2021-08-02T13:38:24.260947Z","shell.execute_reply.started":"2021-08-02T13:38:24.256554Z","shell.execute_reply":"2021-08-02T13:38:24.259899Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# NUM_FOLDS = 5\n# NUM_EPOCHS = 3\n# BATCH_SIZE = 8\n# MAX_LEN = 248\n# EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\nROBERTA_PATH = \"../input/roberta-large-20210712191259-mlm/clrp_roberta_large/\"\nTOKENIZER_PATH = \"../input/roberta-large-20210712191259-mlm/clrp_roberta_large/\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.263453Z","iopub.execute_input":"2021-08-02T13:38:24.264295Z","iopub.status.idle":"2021-08-02T13:38:24.321835Z","shell.execute_reply.started":"2021-08-02T13:38:24.264224Z","shell.execute_reply":"2021-08-02T13:38:24.320777Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.324290Z","iopub.execute_input":"2021-08-02T13:38:24.324645Z","iopub.status.idle":"2021-08-02T13:38:24.601596Z","shell.execute_reply.started":"2021-08-02T13:38:24.324592Z","shell.execute_reply":"2021-08-02T13:38:24.600341Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n                                max_length=config['max_len'],\n                                padding='max_length',truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.604139Z","iopub.execute_input":"2021-08-02T13:38:24.604810Z","iopub.status.idle":"2021-08-02T13:38:24.613402Z","shell.execute_reply.started":"2021-08-02T13:38:24.604764Z","shell.execute_reply":"2021-08-02T13:38:24.612290Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n        config.update({\"output_hidden_states\":True, \n                       \"hidden_dropout_prob\": 0.0,\n                       \"layer_norm_eps\": 1e-7})                       \n        \n        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)\n        #https://towardsdatascience.com/attention-based-deep-multiple-instance-learning-1bb3df857e24\n        # 768: node fully connected layer\n        # 512: node attention layer\n        # self.attention = nn.Sequential(            \n        #     nn.Linear(768, 512),            \n        #     nn.Tanh(),                       \n        #     nn.Linear(512, 1),\n        #     nn.Softmax(dim=1)\n        # )        \n\n        # self.regressor = nn.Sequential(                        \n        #     nn.Linear(768, 1)                        \n        # )\n\n\n        #768 -> 1024\n        #512 -> 768\n        self.attention = nn.Sequential(            \n            nn.Linear(1024, 768),            \n            nn.Tanh(),                       \n            nn.Linear(768, 1),\n            nn.Softmax(dim=1)\n        )        \n\n        self.regressor = nn.Sequential(                        \n            nn.Linear(1024, 1)                        \n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        roberta_output = self.roberta(input_ids=input_ids,\n                                      attention_mask=attention_mask)        \n\n        # There are a total of 13 layers of hidden states.\n        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n        # We take the hidden states from the last Roberta layer.\n        last_layer_hidden_states = roberta_output.hidden_states[-1]\n\n        # The number of cells is MAX_LEN.\n        # The size of the hidden state of each cell is 768 (for roberta-base).\n        # In order to condense hidden states of all cells to a context vector,\n        # we compute a weighted average of the hidden states of all cells.\n        # We compute the weight of each cell, using the attention neural network.\n        weights = self.attention(last_layer_hidden_states)\n                \n        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n        # Now we compute context_vector as the weighted average.\n        # context_vector.shape is BATCH_SIZE x 768\n        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n        \n        # Now we reduce the context vector to the prediction score.\n        return self.regressor(context_vector)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.614824Z","iopub.execute_input":"2021-08-02T13:38:24.615571Z","iopub.status.idle":"2021-08-02T13:38:24.628802Z","shell.execute_reply.started":"2021-08-02T13:38:24.615481Z","shell.execute_reply":"2021-08-02T13:38:24.627627Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def predict(model, data_loader):\n    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n    model.eval()\n\n    result = np.zeros(len(data_loader.dataset))    \n    index = 0\n    \n    with torch.no_grad():\n        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)\n                        \n            pred = model(input_ids, attention_mask)                        \n\n            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n            index += pred.shape[0]\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.630529Z","iopub.execute_input":"2021-08-02T13:38:24.631185Z","iopub.status.idle":"2021-08-02T13:38:24.643129Z","shell.execute_reply.started":"2021-08-02T13:38:24.631138Z","shell.execute_reply":"2021-08-02T13:38:24.641424Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Predict and submit","metadata":{}},{"cell_type":"markdown","source":"## + SVM","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\ntarget = train_data['target'].to_numpy()\nbins = train_data.bins.to_numpy()\n\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n\nconfig = {\n    'batch_size': 8,\n    'max_len': 248,\n    'nfolds':10,\n    'seed':42,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.648362Z","iopub.execute_input":"2021-08-02T13:38:24.648696Z","iopub.status.idle":"2021-08-02T13:38:24.775840Z","shell.execute_reply.started":"2021-08-02T13:38:24.648667Z","shell.execute_reply":"2021-08-02T13:38:24.774624Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Fold取得","metadata":{}},{"cell_type":"code","source":"\ntrain_data.drop(train_data[(train_data.target == 0) & (train_data.standard_error == 0)].index,\n              inplace=True)\ntrain_data.reset_index(drop=True, inplace=True)\n\nNUM_FOLDS = 5\nNUM_EPOCHS = 3\nBATCH_SIZE = 16\nMAX_LEN = 248\nSEED = 1000\n\n\nkfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n\nfor fold, (train_indices, val_indices) in enumerate(kfold.split(train_data)): \n    \n    print(\"********\",fold,\"********\")\n    train_data.loc[val_indices, 'fold'] = fold\n    # traindf1,val_df1 = train_df.iloc[train_indices],train_df.iloc[val_indices]\n\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.777950Z","iopub.execute_input":"2021-08-02T13:38:24.778458Z","iopub.status.idle":"2021-08-02T13:38:24.846087Z","shell.execute_reply.started":"2021-08-02T13:38:24.778425Z","shell.execute_reply":"2021-08-02T13:38:24.845091Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"******** 0 ********\n******** 1 ********\n******** 2 ********\n******** 3 ********\n******** 4 ********\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"             id                                          url_legal  \\\n0     c12129c31                                                NaN   \n1     85aa80a4c                                                NaN   \n2     b69ac6792                                                NaN   \n3     dd1000b26                                                NaN   \n4     37c1b32fb                                                NaN   \n...         ...                                                ...   \n2828  25ca8f498  https://sites.ehe.osu.edu/beyondpenguins/files...   \n2829  2c26db523  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n2830  cd19e2350  https://en.wikibooks.org/wiki/Wikijunior:The_E...   \n2831  15e2e9e7a  https://en.wikibooks.org/wiki/Geometry_for_Ele...   \n2832  5b990ba77  https://en.wikibooks.org/wiki/Wikijunior:Biolo...   \n\n           license                                            excerpt  \\\n0              NaN  When the young people returned to the ballroom...   \n1              NaN  All through dinner time, Mrs. Fayre was somewh...   \n2              NaN  As Roger had predicted, the snow departed as q...   \n3              NaN  And outside before the palace a great garden w...   \n4              NaN  Once upon a time there were Three Bears who li...   \n...            ...                                                ...   \n2828  CC BY-SA 3.0  When you think of dinosaurs and where they liv...   \n2829  CC BY-SA 3.0  So what is a solid? Solids are usually hard be...   \n2830  CC BY-SA 3.0  The second state of matter we will discuss is ...   \n2831  CC BY-SA 3.0  Solids are shapes that you can actually touch....   \n2832  CC BY-SA 3.0  Animals are made of many cells. They eat thing...   \n\n        target  standard_error  bins  fold  \n0    -0.340259        0.464009     7   3.0  \n1    -0.315372        0.480805     7   1.0  \n2    -0.580118        0.476676     6   4.0  \n3    -1.054013        0.450007     5   0.0  \n4     0.247197        0.510845     8   0.0  \n...        ...             ...   ...   ...  \n2828  1.711390        0.646900    11   2.0  \n2829  0.189476        0.535648     8   4.0  \n2830  0.255209        0.483866     8   3.0  \n2831 -0.215279        0.514128     7   1.0  \n2832  0.300779        0.512379     8   4.0  \n\n[2833 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>url_legal</th>\n      <th>license</th>\n      <th>excerpt</th>\n      <th>target</th>\n      <th>standard_error</th>\n      <th>bins</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>c12129c31</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>When the young people returned to the ballroom...</td>\n      <td>-0.340259</td>\n      <td>0.464009</td>\n      <td>7</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>85aa80a4c</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n      <td>-0.315372</td>\n      <td>0.480805</td>\n      <td>7</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b69ac6792</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>As Roger had predicted, the snow departed as q...</td>\n      <td>-0.580118</td>\n      <td>0.476676</td>\n      <td>6</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dd1000b26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>And outside before the palace a great garden w...</td>\n      <td>-1.054013</td>\n      <td>0.450007</td>\n      <td>5</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37c1b32fb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Once upon a time there were Three Bears who li...</td>\n      <td>0.247197</td>\n      <td>0.510845</td>\n      <td>8</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2828</th>\n      <td>25ca8f498</td>\n      <td>https://sites.ehe.osu.edu/beyondpenguins/files...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>When you think of dinosaurs and where they liv...</td>\n      <td>1.711390</td>\n      <td>0.646900</td>\n      <td>11</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2829</th>\n      <td>2c26db523</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>So what is a solid? Solids are usually hard be...</td>\n      <td>0.189476</td>\n      <td>0.535648</td>\n      <td>8</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2830</th>\n      <td>cd19e2350</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:The_E...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>The second state of matter we will discuss is ...</td>\n      <td>0.255209</td>\n      <td>0.483866</td>\n      <td>8</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2831</th>\n      <td>15e2e9e7a</td>\n      <td>https://en.wikibooks.org/wiki/Geometry_for_Ele...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>Solids are shapes that you can actually touch....</td>\n      <td>-0.215279</td>\n      <td>0.514128</td>\n      <td>7</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2832</th>\n      <td>5b990ba77</td>\n      <td>https://en.wikibooks.org/wiki/Wikijunior:Biolo...</td>\n      <td>CC BY-SA 3.0</td>\n      <td>Animals are made of many cells. They eat thing...</td>\n      <td>0.300779</td>\n      <td>0.512379</td>\n      <td>8</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2833 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\n\n### SVM、Ridgeの予測結果提出と　CV計測\ndef run():\n#     foldlist = [4]\n    \n    preds = []\n    scores = []\n\n    svmpreds_list = []\n    ridgepreds_list = []\n    lassopreds_list= []\n\n    for fold in range(5):\n#     for fold in foldlist:\n\n        predssvm = np.zeros((test_data.shape[0]))\n        predsridge = np.zeros((test_data.shape[0]))\n        predslasso = np.zeros((test_data.shape[0]))\n\n        print('fold  :  ',fold)\n        X_train = train_data[train_data[\"fold\"] != fold]\n        y_train = train_data[train_data[\"fold\"] != fold]['target']\n        X_valid = train_data[train_data[\"fold\"] == fold]\n        y_valid = train_data[train_data[\"fold\"] == fold]['target']\n\n        train_embeddings = get_embeddings(X_train,f'../input/roberta-large-20210720020531-sch/model_{fold + 1}.pth')\n        valid_embeddings = get_embeddings(X_valid,f'../input/roberta-large-20210720020531-sch/model_{fold + 1}.pth')\n        test_embeddings = get_embeddings(test_data,f'../input/roberta-large-20210720020531-sch/model_{fold + 1}.pth')\n\n\n        model = SVR(C=10,kernel='rbf',gamma='auto')\n        model_ridge = Ridge(alpha=20)\n        model_lasso = Lasso(alpha=0.05)\n\n        model.fit(train_embeddings,y_train)\n        model_ridge.fit(train_embeddings,y_train)\n        model_lasso.fit(train_embeddings,y_train)\n\n        prediction = model.predict(valid_embeddings)\n        pred_ridge = model_ridge.predict(valid_embeddings)\n        pred_lasso = model_lasso.predict(valid_embeddings)\n\n    #     preds += model.predict(X_test)\n    #     preds_ridge += model_ridge.predict(X_test)\n\n        pred_mean = (prediction + pred_ridge + pred_lasso)/3\n        score = rmse_score(y_valid, pred_mean)\n\n        preds.append(pred_mean)\n\n        score = rmse_score(y_valid, pred_mean)\n        scores.append(score)\n        print(f'fold {fold} score is  : ',score)\n        print(scores)\n\n        predssvm += model.predict(test_embeddings)\n        predsridge += model_ridge.predict(test_embeddings)\n        predslasso += model_lasso.predict(test_embeddings)\n        \n\n        svmpreds_list.append(predssvm)\n        ridgepreds_list.append(predsridge)\n        lassopreds_list.append(predslasso)\n        \n        del model,model_ridge,train_embeddings,valid_embeddings,test_embeddings\n        gc.collect\n\n    print('mean  :  ',np.array(scores).mean())\n    \n    return (np.array(svmpreds_list).mean(axis=0) + np.array(ridgepreds_list).mean(axis=0) + np.array(lassopreds_list).mean(axis=0))/3\n#     return (np.array(svmpreds_list).mean(axis=0) + np.array(ridgepreds_list).mean(axis=0))/2","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:53:56.692734Z","iopub.execute_input":"2021-08-02T13:53:56.693221Z","iopub.status.idle":"2021-08-02T13:53:56.715099Z","shell.execute_reply.started":"2021-08-02T13:53:56.693185Z","shell.execute_reply":"2021-08-02T13:53:56.713613Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    #cuda使えたら使う構文\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    model = Model()\n    model.load_state_dict(torch.load(path))\n    model.to(device)\n    model.eval()\n    \n    #tokenizer = AutoTokenizer.from_pretrained('../input/clrp-roberta-base/clrp_roberta_base')\n    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n    \n    ds = CLRPDataset(df, tokenizer)\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    #以下でpredictionsを抽出するために使った構文を使ってembeddingsをreturnしている.\n    #SVMの手法とは、embeddingsの意味は？\n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs.detach().cpu().numpy()\n            embeddings.extend(outputs)\n    \n    gc.collect\n    \n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.869044Z","iopub.execute_input":"2021-08-02T13:38:24.869508Z","iopub.status.idle":"2021-08-02T13:38:24.883499Z","shell.execute_reply.started":"2021-08-02T13:38:24.869467Z","shell.execute_reply":"2021-08-02T13:38:24.882398Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\ntrain_embeddings2 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_2.pth')\ntrain_embeddings3 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_3.pth')\ntrain_embeddings4 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_4.pth')\ntrain_embeddings5 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_5.pth')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:38:24.885272Z","iopub.execute_input":"2021-08-02T13:38:24.886143Z","iopub.status.idle":"2021-08-02T13:48:08.981512Z","shell.execute_reply.started":"2021-08-02T13:38:24.886098Z","shell.execute_reply":"2021-08-02T13:48:08.978874Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"cuda is used\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-20210712191259-mlm/clrp_roberta_large/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n355it [01:27,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"cuda is used\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-20210712191259-mlm/clrp_roberta_large/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n355it [01:26,  4.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"cuda is used\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-20210712191259-mlm/clrp_roberta_large/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n355it [01:26,  4.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"cuda is used\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-20210712191259-mlm/clrp_roberta_large/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n355it [01:26,  4.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"cuda is used\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at ../input/roberta-large-20210712191259-mlm/clrp_roberta_large/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n355it [01:27,  4.06it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"#train/testでembeddingsを取得している\n# train_embeddings1 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n# test_embeddings1 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n\n# train_embeddings2 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n# test_embeddings2 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n\n# train_embeddings3 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n# test_embeddings3 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_3.pth')\n\n# train_embeddings4 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_4.pth')\n# test_embeddings4 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_4.pth')\n\n# train_embeddings5 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_5.pth')\n# test_embeddings5 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_5.pth')","metadata":{"execution":{"iopub.status.busy":"2021-07-29T05:44:12.341811Z","iopub.execute_input":"2021-07-29T05:44:12.342532Z","iopub.status.idle":"2021-07-29T05:44:12.352817Z","shell.execute_reply.started":"2021-07-29T05:44:12.342487Z","shell.execute_reply":"2021-07-29T05:44:12.351833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#SVMをアンサンブル処理している\ndef get_preds_svm(X,y,X_test,bins=bins,nfolds=10,C=10,kernel='rbf'):\n    scores = list()\n    preds = np.zeros((X_test.shape[0]))\n    preds_ridge = np.zeros((X_test.shape[0]))\n    \n    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n        model = SVR(C=5,kernel=kernel,gamma='auto')\n        model_ridge = Ridge(alpha=10)\n        #print(train_idx)\n        #print(valid_idx)\n        X_train,y_train = X[train_idx], y[train_idx]\n        X_valid,y_valid = X[valid_idx], y[valid_idx]\n        \n        model.fit(X_train,y_train)\n        model_ridge.fit(X_train, y_train)\n        \n        prediction = model.predict(X_valid)\n        pred_ridge = model_ridge.predict(X_valid)\n        \n        #score = rmse_score(prediction,y_valid)\n        score = rmse_score(y_valid, prediction)\n        print(f'Fold {k} , rmse score: {score}')\n        \n        scores.append(score)\n        preds += model.predict(X_test)\n        preds_ridge += model_ridge.predict(X_test)\n        \n        \n        \n    print(\"mean rmse\",np.mean(scores))\n    return (np.array(preds)/nfolds + np.array(preds_ridge)/nfolds)/2","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:48:08.986181Z","iopub.execute_input":"2021-08-02T13:48:08.986670Z","iopub.status.idle":"2021-08-02T13:48:09.005447Z","shell.execute_reply.started":"2021-08-02T13:48:08.986621Z","shell.execute_reply":"2021-08-02T13:48:09.004070Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\n# def run():\n#     preds = []\n#     scores = []\n\n#     svmpreds_list = []\n#     ridgepreds_list = []\n#     lassopreds_list = []\n\n#     for fold in range(5):\n\n#         predssvm = np.zeros((test_df.shape[0]))\n#         predsridge = np.zeros((test_df.shape[0]))\n#         predslasso= np.zeros((test_df.shape[0]))\n\n#         print('fold  :  ',fold)\n#         X_train = train_data[train_data[\"kfold\"] != fold]\n#         y_train = train_data[train_data[\"kfold\"] != fold]['target']\n#         X_valid = train_data[train_data[\"kfold\"] == fold]\n#         y_valid = train_data[train_data[\"kfold\"] == fold]['target']\n\n#         train_embeddings = get_embeddings(X_train,f'../input/roberta-base-20210730175534-stk/model_{fold + 1}.pth')\n#         valid_embeddings = get_embeddings(X_valid,f'../input/roberta-base-20210730175534-stk/model_{fold + 1}.pth')\n#         test_embeddings = get_embeddings(test_data,f'../input/roberta-base-20210730175534-stk/model_{fold + 1}.pth')\n\n\n# #         model = SVR(C=5,kernel='rbf',gamma='auto')\n#         model_ridge = Ridge(alpha=20)\n#         model_lasso = Lasso(alpha=0.05)\n# #         model_xgb = XGBRegressor(booster = 'gblinear',lamdba = 2)#min_child_weight=0.5\n\n# #         model.fit(train_embeddings,y_train)\n#         model_ridge.fit(train_embeddings,y_train)\n#         model_lasso.fit(train_embeddings,y_train)\n\n# #         prediction_svm = model.predict(valid_embeddings)\n#         prediction_ridge = model_ridge.predict(valid_embeddings)\n#         prediction_lasso = model_lasso.predict(valid_embeddings)\n\n#     #     preds += model.predict(X_test)\n#     #     preds_ridge += model_ridge.predict(X_test)\n\n# #         pred_mean = (prediction_svm + prediction_ridge)/2\n#         pred_mean = (prediction_ridge + prediction_lasso)/2\n#         score = rmse_score(y_valid, pred_mean)\n\n#         preds.append(pred_mean)\n\n#         score = rmse_score(y_valid, pred_mean)\n#         scores.append(score)\n#         print(f'fold {fold} score is  : ',score)\n#         print(scores)\n\n# #         predssvm += model.predict(test_embeddings)\n#         predsridge += model_ridge.predict(test_embeddings)\n#         predslasso += model_lasso.predict(test_embeddings)\n\n# #         svmpreds_list.append(predssvm)\n#         ridgepreds_list.append(predsridge)\n#         lassopreds_list.append(predslasso)\n        \n#     print('mean  :  ',np.array(scores).mean())\n    \n#     return (np.array(ridgepreds_list).mean(axis=0) + np.array(lassopreds_list).mean(axis=0))/2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = run()\n\nsample.target = pred\nsample.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-02T13:54:07.252900Z","iopub.execute_input":"2021-08-02T13:54:07.253307Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"fold  :   0\ncuda is used\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 出力用","metadata":{}},{"cell_type":"code","source":"# # train/testでembeddingsを取得している\n# train_embeddings1 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n# test_embeddings1 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n\n# train_embeddings2 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n# test_embeddings2 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n\n# train_embeddings3 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_1.pth')\n# test_embeddings3 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_3.pth')\n\n# train_embeddings4 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_4.pth')\n# test_embeddings4 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_4.pth')\n\n# train_embeddings5 =  get_embeddings(train_data,'../input/roberta-large-20210720020531-sch/model_5.pth')\n# test_embeddings5 = get_embeddings(test_data,'../input/roberta-large-20210720020531-sch/model_5.pth')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.linear_model import Ridge\n\n# preds = []\n# for i in range(5):\n#     train_embeddings =  get_embeddings(train_data, f'../input/roberta-large-20210720020531-sch/model_{i+1}.pth')\n#     test_embeddings = get_embeddings(test_data, f'../input/roberta-large-20210720020531-sch/model_{i+1}.pth')\n#     svm_pred = get_preds_svm(train_embeddings, target, test_embeddings)\n#     preds.append(svm_pred)\n#     del train_embeddings\n#     del test_embeddings\n#     del svm_pred\n#     gc.collect()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(5):\n#     print(preds[i])\n\n# svm_preds = (preds[0] + preds[1] + preds[2] + preds[3] + preds[4])/5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample.target = svm_preds\n# sample.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}