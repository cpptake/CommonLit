{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "convinced-istanbul",
   "metadata": {
    "papermill": {
     "duration": 0.014344,
     "end_time": "2021-08-03T14:48:15.235888",
     "exception": false,
     "start_time": "2021-08-03T14:48:15.221544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "テスト\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-stocks",
   "metadata": {
    "papermill": {
     "duration": 0.012723,
     "end_time": "2021-08-03T14:48:15.262635",
     "exception": false,
     "start_time": "2021-08-03T14:48:15.249912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "threaded-hotel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T14:48:15.295627Z",
     "iopub.status.busy": "2021-08-03T14:48:15.293426Z",
     "iopub.status.idle": "2021-08-03T14:48:25.182009Z",
     "shell.execute_reply": "2021-08-03T14:48:25.181270Z",
     "shell.execute_reply.started": "2021-08-03T14:44:58.407323Z"
    },
    "papermill": {
     "duration": 9.907049,
     "end_time": "2021-08-03T14:48:25.182234",
     "exception": false,
     "start_time": "2021-08-03T14:48:15.275185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import gc; gc.enable()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torch.utils.data import Dataset\n",
    "# from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, SequentialSampler, DataLoader\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, logging\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Input,LSTM,Bidirectional,Embedding,Dense, Conv1D, Dropout , MaxPool1D , MaxPooling1D, GlobalAveragePooling2D , GlobalAveragePooling1D , GlobalMaxPooling1D , concatenate , Flatten\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.models import Model,load_model,save_model , model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint, EarlyStopping ,LearningRateScheduler\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from transformers import TFBertModel, BertTokenizerFast , BertTokenizer , RobertaTokenizerFast , TFRobertaModel , RobertaConfig , TFAutoModel , AutoTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "victorian-reminder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T14:48:25.216724Z",
     "iopub.status.busy": "2021-08-03T14:48:25.215997Z",
     "iopub.status.idle": "2021-08-03T14:48:25.323558Z",
     "shell.execute_reply": "2021-08-03T14:48:25.322967Z",
     "shell.execute_reply.started": "2021-08-03T14:45:06.230461Z"
    },
    "papermill": {
     "duration": 0.127691,
     "end_time": "2021-08-03T14:48:25.323746",
     "exception": false,
     "start_time": "2021-08-03T14:48:25.196055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n",
    "submission_df = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-interval",
   "metadata": {
    "papermill": {
     "duration": 0.01302,
     "end_time": "2021-08-03T14:48:25.350289",
     "exception": false,
     "start_time": "2021-08-03T14:48:25.337269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# roberta base embedding Lasso & Ridge CV: 0.4753\n",
    "https://www.kaggle.com/iamnishipy/submit-my-roberta-base-svm?scriptVersionId=69168038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "canadian-animation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T14:48:25.407468Z",
     "iopub.status.busy": "2021-08-03T14:48:25.386028Z",
     "iopub.status.idle": "2021-08-03T14:48:25.784044Z",
     "shell.execute_reply": "2021-08-03T14:48:25.784613Z",
     "shell.execute_reply.started": "2021-08-03T14:45:06.331045Z"
    },
    "papermill": {
     "duration": 0.421541,
     "end_time": "2021-08-03T14:48:25.784816",
     "exception": false,
     "start_time": "2021-08-03T14:48:25.363275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 248\n",
    "EVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "ROBERTA_PATH = \"../input/clrp-roberta-base/clrp_roberta_base/\"\n",
    "TOKENIZER_PATH = \"../input/clrp-roberta-base/clrp_roberta_base/\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "\n",
    "train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n",
    "test_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "\n",
    "\n",
    "num_bins = int(np.floor(1 + np.log2(len(train_data))))\n",
    "train_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n",
    "\n",
    "target = train_data['target'].to_numpy()\n",
    "bins = train_data.bins.to_numpy()\n",
    "\n",
    "\n",
    "def rmse_score(y_true,y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true,y_pred))\n",
    "\n",
    "config = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'max_len': MAX_LEN,\n",
    "    'nfolds':10,\n",
    "    'seed':42,\n",
    "}\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONASSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed=config['seed'])\n",
    "\n",
    "\n",
    "class CLRPDataset(Dataset):\n",
    "    def __init__(self,df,tokenizer):\n",
    "        self.excerpt = df['excerpt'].to_numpy()\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n",
    "                                max_length=config['max_len'],\n",
    "                                padding='max_length',truncation=True)\n",
    "        return encode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.excerpt)\n",
    "    \n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(768, 512),            \n",
    "            nn.Tanh(),                       \n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(                        \n",
    "            nn.Linear(768, 1)                        \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)        \n",
    "\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)\n",
    "    \n",
    "\n",
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_embeddings(df,path,plot_losses=True, verbose=True):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"{device} is used\")\n",
    "            \n",
    "    model = Model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    #tokenizer = AutoTokenizer.from_pretrained('../input/clrp-roberta-base/clrp_roberta_base')\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "    \n",
    "    ds = CLRPDataset(df, tokenizer)\n",
    "    dl = DataLoader(ds,\n",
    "                  batch_size = config[\"batch_size\"],\n",
    "                  shuffle=False,\n",
    "                  num_workers = 4,\n",
    "                  pin_memory=True,\n",
    "                  drop_last=False\n",
    "                 )\n",
    "        \n",
    "    #以下でpredictionsを抽出するために使った構文を使ってembeddingsをreturnしている.\n",
    "    #SVMの手法とは、embeddingsの意味は？\n",
    "    embeddings = list()\n",
    "    with torch.no_grad():\n",
    "        for i, inputs in tqdm(enumerate(dl)):\n",
    "            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            embeddings.extend(outputs)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "\n",
    "def get_preds_svm(X,y,X_test,bins=bins,nfolds=10,C=10,kernel='rbf'):\n",
    "    scores = list()\n",
    "    preds = np.zeros((X_test.shape[0]))\n",
    "    preds_ridge = np.zeros((X_test.shape[0]))\n",
    "    preds_lasso = np.zeros((X_test.shape[0]))\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n",
    "    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n",
    "        model = SVR(C=5,kernel=kernel,gamma='auto')\n",
    "        model_ridge = Ridge(alpha=20)\n",
    "        model_lasso = Lasso(alpha=0.05)\n",
    "        #print(train_idx)\n",
    "        #print(valid_idx)\n",
    "        X_train,y_train = X[train_idx], y[train_idx]\n",
    "        X_valid,y_valid = X[valid_idx], y[valid_idx]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        model_ridge.fit(X_train, y_train)\n",
    "        model_lasso.fit(X_train,y_train)\n",
    "        \n",
    "        prediction = model.predict(X_valid)\n",
    "        pred_ridge = model_ridge.predict(X_valid)\n",
    "        pred_lasso = model_lasso.predict(X_valid)\n",
    "        \n",
    "        pred_mean = (prediction + pred_ridge + pred_lasso)/3\n",
    "        \n",
    "        #score = rmse_score(prediction,y_valid)\n",
    "        score = rmse_score(y_valid, pred_mean)\n",
    "        print(f'Fold {k} , rmse score: {score}')\n",
    "        \n",
    "        scores.append(score)\n",
    "        preds += model.predict(X_test)\n",
    "        preds_ridge += model_ridge.predict(X_test)\n",
    "        preds_lasso += model_lasso.predict(X_test)\n",
    "        \n",
    "    print(\"mean rmse\",np.mean(scores))\n",
    "    return (np.array(preds)/nfolds + np.array(preds_ridge)/nfolds + np.array(preds_lasso)/nfolds)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thousand-foundation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T14:48:25.827136Z",
     "iopub.status.busy": "2021-08-03T14:48:25.826396Z",
     "iopub.status.idle": "2021-08-03T14:48:25.955789Z",
     "shell.execute_reply": "2021-08-03T14:48:25.956367Z",
     "shell.execute_reply.started": "2021-08-03T14:45:06.683042Z"
    },
    "papermill": {
     "duration": 0.157962,
     "end_time": "2021-08-03T14:48:25.956571",
     "exception": false,
     "start_time": "2021-08-03T14:48:25.798609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>kfold</th>\n",
       "      <th>bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56a925239</td>\n",
       "      <td>https://kids.frontiersin.org/article/10.3389/f...</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>What makes epilepsy and seizures so mysterious...</td>\n",
       "      <td>0.105749</td>\n",
       "      <td>0.492565</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bf24448fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anywhere there is a frontier, where there are ...</td>\n",
       "      <td>-1.866238</td>\n",
       "      <td>0.510911</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7cad0f936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A great violinist, Ole Bull by name, visited t...</td>\n",
       "      <td>-0.578482</td>\n",
       "      <td>0.471768</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>284eaa5ad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As to surface-slope its measurement—from nearl...</td>\n",
       "      <td>-3.639936</td>\n",
       "      <td>0.603819</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>91e87e7dc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hans stopped snoring and awoke at supper-time....</td>\n",
       "      <td>-0.186015</td>\n",
       "      <td>0.492731</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         id                                          url_legal  \\\n",
       "0           0  56a925239  https://kids.frontiersin.org/article/10.3389/f...   \n",
       "1           1  bf24448fb                                                NaN   \n",
       "2           2  7cad0f936                                                NaN   \n",
       "3           3  284eaa5ad                                                NaN   \n",
       "4           4  91e87e7dc                                                NaN   \n",
       "\n",
       "     license                                            excerpt    target  \\\n",
       "0  CC BY 4.0  What makes epilepsy and seizures so mysterious...  0.105749   \n",
       "1        NaN  Anywhere there is a frontier, where there are ... -1.866238   \n",
       "2        NaN  A great violinist, Ole Bull by name, visited t... -0.578482   \n",
       "3        NaN  As to surface-slope its measurement—from nearl... -3.639936   \n",
       "4        NaN  Hans stopped snoring and awoke at supper-time.... -0.186015   \n",
       "\n",
       "   standard_error  kfold  bins  \n",
       "0        0.492565      1     8  \n",
       "1        0.510911      3     4  \n",
       "2        0.471768      2     6  \n",
       "3        0.603819      1     0  \n",
       "4        0.492731      2     7  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('../input/commonlit-train-dataset/train_stratiKfold.csv')\n",
    "\n",
    "train_data.drop(train_data[(train_data.target == 0) & (train_data.standard_error == 0)].index,\n",
    "              inplace=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 248\n",
    "SEED = 1000\n",
    "\n",
    "\n",
    "# kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "\n",
    "# for fold, (train_indices, val_indices) in enumerate(kfold.split(train_data)): \n",
    "    \n",
    "#     print(\"********\",fold,\"********\")\n",
    "#     train_data.loc[val_indices, 'fold'] = fold\n",
    "#     # traindf1,val_df1 = train_df.iloc[train_indices],train_df.iloc[val_indices]\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-focus",
   "metadata": {
    "papermill": {
     "duration": 0.013417,
     "end_time": "2021-08-03T14:48:25.985015",
     "exception": false,
     "start_time": "2021-08-03T14:48:25.971598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "civilian-special",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T14:48:26.027459Z",
     "iopub.status.busy": "2021-08-03T14:48:26.026512Z",
     "iopub.status.idle": "2021-08-03T14:48:26.030920Z",
     "shell.execute_reply": "2021-08-03T14:48:26.030362Z",
     "shell.execute_reply.started": "2021-08-03T14:45:06.820985Z"
    },
    "papermill": {
     "duration": 0.032248,
     "end_time": "2021-08-03T14:48:26.031071",
     "exception": false,
     "start_time": "2021-08-03T14:48:25.998823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def run():\n",
    "    preds = []\n",
    "    scores = []\n",
    "\n",
    "    svmpreds_list = []\n",
    "    ridgepreds_list = []\n",
    "    lassopreds_list = []\n",
    "\n",
    "    for fold in range(5):\n",
    "\n",
    "        predssvm = np.zeros((test_df.shape[0]))\n",
    "        predsridge = np.zeros((test_df.shape[0]))\n",
    "        predslasso= np.zeros((test_df.shape[0]))\n",
    "\n",
    "        print('fold  :  ',fold)\n",
    "        X_train = train_data[train_data[\"kfold\"] != fold]\n",
    "        y_train = train_data[train_data[\"kfold\"] != fold]['target']\n",
    "        X_valid = train_data[train_data[\"kfold\"] == fold]\n",
    "        y_valid = train_data[train_data[\"kfold\"] == fold]['target']\n",
    "\n",
    "        train_embeddings = get_embeddings(X_train,f'../input/roberta-base-20210730175534-stk/model_{fold + 1}.pth')\n",
    "        valid_embeddings = get_embeddings(X_valid,f'../input/roberta-base-20210730175534-stk/model_{fold + 1}.pth')\n",
    "        test_embeddings = get_embeddings(test_data,f'../input/roberta-base-20210730175534-stk/model_{fold + 1}.pth')\n",
    "\n",
    "\n",
    "#         model = SVR(C=5,kernel='rbf',gamma='auto')\n",
    "        model_ridge = Ridge(alpha=20)\n",
    "        model_lasso = Lasso(alpha=0.05)\n",
    "#         model_xgb = XGBRegressor(booster = 'gblinear',lamdba = 2)#min_child_weight=0.5\n",
    "\n",
    "#         model.fit(train_embeddings,y_train)\n",
    "        model_ridge.fit(train_embeddings,y_train)\n",
    "        model_lasso.fit(train_embeddings,y_train)\n",
    "\n",
    "#         prediction_svm = model.predict(valid_embeddings)\n",
    "        prediction_ridge = model_ridge.predict(valid_embeddings)\n",
    "        prediction_lasso = model_lasso.predict(valid_embeddings)\n",
    "\n",
    "    #     preds += model.predict(X_test)\n",
    "    #     preds_ridge += model_ridge.predict(X_test)\n",
    "\n",
    "#         pred_mean = (prediction_svm + prediction_ridge)/2\n",
    "        pred_mean = (prediction_ridge + prediction_lasso)/2\n",
    "        score = rmse_score(y_valid, pred_mean)\n",
    "\n",
    "        preds.append(pred_mean)\n",
    "\n",
    "        score = rmse_score(y_valid, pred_mean)\n",
    "        scores.append(score)\n",
    "        print(f'fold {fold} score is  : ',score)\n",
    "        print(scores)\n",
    "\n",
    "#         predssvm += model.predict(test_embeddings)\n",
    "        predsridge += model_ridge.predict(test_embeddings)\n",
    "        predslasso += model_lasso.predict(test_embeddings)\n",
    "\n",
    "#         svmpreds_list.append(predssvm)\n",
    "        ridgepreds_list.append(predsridge)\n",
    "        lassopreds_list.append(predslasso)\n",
    "        \n",
    "    print('mean  :  ',np.array(scores).mean())\n",
    "    \n",
    "    return (np.array(ridgepreds_list).mean(axis=0) + np.array(lassopreds_list).mean(axis=0))/2\n",
    "#     return (np.array(svmpreds_list).mean(axis=0) + np.array(ridgepreds_list).mean(axis=0) + np.array(lassopreds_list).mean(axis=0))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "derived-ebony",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T14:48:26.064983Z",
     "iopub.status.busy": "2021-08-03T14:48:26.063885Z",
     "iopub.status.idle": "2021-08-03T14:52:23.258470Z",
     "shell.execute_reply": "2021-08-03T14:52:23.257894Z"
    },
    "papermill": {
     "duration": 237.213527,
     "end_time": "2021-08-03T14:52:23.258686",
     "exception": false,
     "start_time": "2021-08-03T14:48:26.045159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  :   0\n",
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "142it [00:20,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "36it [00:04,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 score is  :  0.46943715167658834\n",
      "[0.46943715167658834]\n",
      "fold  :   1\n",
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "142it [00:19,  7.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "36it [00:05,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 score is  :  0.47681086999077194\n",
      "[0.46943715167658834, 0.47681086999077194]\n",
      "fold  :   2\n",
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "142it [00:19,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "36it [00:05,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 2 score is  :  0.45202914859632504\n",
      "[0.46943715167658834, 0.47681086999077194, 0.45202914859632504]\n",
      "fold  :   3\n",
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "142it [00:19,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "36it [00:05,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3 score is  :  0.4631896225857212\n",
      "[0.46943715167658834, 0.47681086999077194, 0.45202914859632504, 0.4631896225857212]\n",
      "fold  :   4\n",
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "142it [00:19,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "36it [00:05,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../input/clrp-roberta-base/clrp_roberta_base/ and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 4 score is  :  0.5150616164873529\n",
      "[0.46943715167658834, 0.47681086999077194, 0.45202914859632504, 0.4631896225857212, 0.5150616164873529]\n",
      "mean  :   0.4753056818673519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.47041614, -0.65597635, -0.32244206, -2.42862616, -1.64267496,\n",
       "       -1.37886902,  0.12796896])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_lassoridge_pred = run()\n",
    "roberta_lassoridge_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-carol",
   "metadata": {
    "papermill": {
     "duration": 0.374628,
     "end_time": "2021-08-03T14:52:23.975382",
     "exception": false,
     "start_time": "2021-08-03T14:52:23.600754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-symphony",
   "metadata": {
    "papermill": {
     "duration": 0.356298,
     "end_time": "2021-08-03T14:52:24.690926",
     "exception": false,
     "start_time": "2021-08-03T14:52:24.334628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cross-perry",
   "metadata": {
    "papermill": {
     "duration": 0.364605,
     "end_time": "2021-08-03T14:52:25.416949",
     "exception": false,
     "start_time": "2021-08-03T14:52:25.052344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Emsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "floral-poetry",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T14:52:26.156041Z",
     "iopub.status.busy": "2021-08-03T14:52:26.154710Z",
     "iopub.status.idle": "2021-08-03T14:52:26.377161Z",
     "shell.execute_reply": "2021-08-03T14:52:26.376195Z"
    },
    "papermill": {
     "duration": 0.602175,
     "end_time": "2021-08-03T14:52:26.377380",
     "exception": false,
     "start_time": "2021-08-03T14:52:25.775205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id    target\n",
      "0  c0f722661 -0.470416\n",
      "1  f0953f0a5 -0.655976\n",
      "2  0df072751 -0.322442\n",
      "3  04caf4e0c -2.428626\n",
      "4  0e63f8bea -1.642675\n",
      "5  12537fe78 -1.378869\n",
      "6  965e592c0  0.127969\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "\n",
    "predictions = pd.DataFrame()\n",
    "# predictions = y_test * 0.6 + svm_ridge_preds * 0.2 + roberta_svm_ridge_preds * 0.2\n",
    "\n",
    "## ver10 t5_large_svm利用\n",
    "# predictions = y_test * 0.6 + svm_ridge_pred * 0.2 + roberta_svm_ridge_preds * 0.2 \n",
    "\n",
    "# ## ver12 roberta meanpooling , stacking + blending + t5_large_svm + nishipy roberta svm利用\n",
    "# blending_pred =  (nishipy_roberta + nishipy_robertalarge + robertalarge_meanpool + robertabase_meanpool)/3\n",
    "# predictions = stacking_pred * 0.3 + blending_pred * 0.3 + svm_ridge_pred * 0.2 + roberta_svm_ridge_preds * 0.2 \n",
    "\n",
    "## ver14 エラーの原因調査　SVMモデルを削除して　Roberta meanが悪いのか切り分け\n",
    "# blending_pred =  (nishipy_roberta + nishipy_robertalarge + robertalarge_meanpool + robertabase_meanpool)/4\n",
    "# predictions = stacking_pred * 0.3 + blending_pred * 0.3 + large_svmridge_pred * 0.2 + roberta_svmridge_pred * 0.2\n",
    "\n",
    "# ## ver17\n",
    "# blending_pred =  (nishipy_roberta + nishipy_robertalarge + robertalarge_meanpool)/3\n",
    "# predictions = stacking_pred * 0.3 + blending_pred * 0.3 + large_svmridge_pred * 0.2 + roberta_svmridge_pred * 0.2\n",
    "\n",
    "# ## ver17\n",
    "# blending_pred =  (nishipy_roberta + nishipy_robertalarge + robertalarge_meanpool)/3\n",
    "# predictions = stacking_pred * 0.3 + blending_pred * 0.3 + ((large_svmridge_pred + roberta_svmridge_pred + t5_embedding_pred)/3) * 0.4\n",
    "\n",
    "## ver22\n",
    "# blending_pred =  (nishipy_roberta + nishipy_robertalarge + robertalarge_meanpool)/3\n",
    "# predictions = stacking_pred * 0.2 + blending_pred * 0.25 + roberta_svmridge_pred * 0.2 + t5_embedding_pred * 0.35\n",
    "\n",
    "## ver22\n",
    "# blending_pred =  (nishipy_roberta + nishipy_robertalarge + robertalarge_meanpool + robertabase_meanpool)/4\n",
    "# predictions = stacking_pred * 0.25 + blending_pred * 0.25 + ((roberta_svmridge_pred + large_svmridge_pred + t5_embedding_pred  + svm_ridge_preds)/4) * 0.5\n",
    "\n",
    "# blending_pred =  (nishipy_roberta + nishipy_robertalarge + robertalarge_meanpool)/3\n",
    "# predictions = stacking_pred * 0.25 + blending_pred * 0.25 + ((roberta_lassoridge_pred + t5_embedding_pred)/2) * 0.5\n",
    "\n",
    "submission_df.target = roberta_lassoridge_pred\n",
    "print(submission_df)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-winner",
   "metadata": {
    "papermill": {
     "duration": 0.357141,
     "end_time": "2021-08-03T14:52:27.092876",
     "exception": false,
     "start_time": "2021-08-03T14:52:26.735735",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Emsemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-melissa",
   "metadata": {
    "papermill": {
     "duration": 0.357318,
     "end_time": "2021-08-03T14:52:27.807393",
     "exception": false,
     "start_time": "2021-08-03T14:52:27.450075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 264.978209,
   "end_time": "2021-08-03T14:52:31.848288",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-03T14:48:06.870079",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
